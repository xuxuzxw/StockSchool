import glob
import logging
import os
import shutil
from datetime import datetime
from pathlib import Path

#!/usr/bin/env python3
"""
StockSchoolé¡¹ç›®æ¸…ç†è„šæœ¬
ç”¨äºæ¸…ç†ä¸´æ—¶æ–‡ä»¶ã€è¿‡æ—¶æ–‡æ¡£å’Œæ•´ç†é¡¹ç›®ç»“æ„
"""


class ProjectCleaner:
    """ç±»æè¿°"""
        self.project_root = Path(project_root)
        self.cleanup_log = []

        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)

    def log_cleanup(self, action, path, description=""):
        """è®°å½•æ¸…ç†æ“ä½œ"""
        entry = {
            "timestamp": datetime.now().isoformat(),
            "action": action,
            "path": str(path),
            "description": description
        }
        self.cleanup_log.append(entry)
        self.logger.info(f"{action}: {path} - {description}")

    def find_temp_files(self):
        """æŸ¥æ‰¾ä¸´æ—¶æ–‡ä»¶"""
        temp_patterns = [
            "**/*.tmp",
            "**/*.log",
            "**/*.pyc",
            "**/__pycache__/**",
            "**/.pytest_cache/**",
            "**/.mypy_cache/**",
            "**/.coverage",
            "**/htmlcov/**",
            "**/.tox/**",
            "**/dist/**",
            "**/build/**",
            "**/*.egg-info/**",
            "**/.DS_Store",
            "**/Thumbs.db",
            "**/*.bak",
            "**/*.swp",
            "**/*.swo",
            "**/*~",
        ]

        temp_files = []
        for pattern in temp_patterns:
            files = self.project_root.glob(pattern)
            temp_files.extend(files)

        return temp_files

    def find_outdated_docs(self):
        """æŸ¥æ‰¾è¿‡æ—¶çš„æ–‡æ¡£æ–‡ä»¶"""
        outdated_docs = []

        # éœ€è¦æ¸…ç†çš„è¿‡æ—¶æ–‡æ¡£
        outdated_patterns = [
            "docs/1comprehensive_review.md",
            "docs/2refactoring_plan.md",
            "docs/3.md",
            "docs/REFACTORING_PLAN.md",  # ä¸é‡æ„è®¡åˆ’é‡å¤
            "docs/DEPLOYMENT_SUMMARY.md",  # ä¸éƒ¨ç½²æŒ‡å—é‡å¤
            "docs/README_STAGE3.md",  # è¿‡æ—¶çš„README
            "docs/data_sync_refactoring_log.md",  # ä¸é‡æ„æŠ¥å‘Šé‡å¤
            "docs/factor_calculation_engine_review.md",  # ä¸æŠ€æœ¯æŒ‡å—é‡å¤
            "docs/factor_engine_refactoring_summary.md",  # ä¸é‡æ„æŠ¥å‘Šé‡å¤
        ]

        for pattern in outdated_patterns:
            files = self.project_root.glob(pattern)
            outdated_docs.extend(files)

        return outdated_docs

    def merge_similar_docs(self):
        """åˆå¹¶ç›¸ä¼¼çš„æ–‡æ¡£å†…å®¹"""
        merges = []

        # æ£€æŸ¥å¯ä»¥åˆå¹¶çš„æ–‡æ¡£
        doc_pairs = [
            ("docs/data_sync_refactoring.md", "docs/data_sync_refactoring_log.md"),
            ("docs/factor_calculation_technical_guide.md", "docs/factor_calculation_engine_review.md"),
        ]

        for main_doc, secondary_doc in doc_pairs:
            main_path = self.project_root / main_doc
            secondary_path = self.project_root / secondary_doc

            if main_path.exists() and secondary_path.exists():
                merges.append((main_path, secondary_path))

        return merges

    def update_readme(self):
        """æ›´æ–°README.mdï¼Œæ•´åˆæœ€æ–°å†…å®¹"""
        readme_path = self.project_root / "README.md"

        if not readme_path.exists():
            return False

        # è¯»å–å½“å‰å†…å®¹
        with open(readme_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ·»åŠ ç¬¬äºŒé˜¶æ®µä¼˜åŒ–å†…å®¹
        stage2_content = """
## ğŸš€ ç¬¬äºŒé˜¶æ®µä¼˜åŒ– (v2.0.0)

### æ€§èƒ½ä¼˜åŒ–
- **å¹¶è¡Œè®¡ç®—å¼•æ“**: å¤šè¿›ç¨‹å¹¶è¡Œå› å­è®¡ç®—ï¼Œæ”¯æŒCPU/GPUåŠ é€Ÿ
- **æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ**: Redis+å†…å­˜å¤šçº§ç¼“å­˜ï¼ŒLRUæ·˜æ±°ç­–ç•¥
- **è´Ÿè½½å‡è¡¡**: Nginxåå‘ä»£ç†ï¼Œæ”¯æŒå¤šå®ä¾‹éƒ¨ç½²
- **æ‰¹å¤„ç†ä¼˜åŒ–**: æ™ºèƒ½æ‰¹é‡å¤§å°è®¡ç®—ï¼Œå†…å­˜è‡ªé€‚åº”ç®¡ç†

### ç›‘æ§å¢å¼º
- **å®æ—¶ç›‘æ§**: Prometheus+Grafanaç›‘æ§æ ˆ
- **æ•°æ®è´¨é‡ç›‘æ§**: å®æ—¶æ•°æ®è´¨é‡æ£€æŸ¥å’Œå‘Šè­¦
- **æ€§èƒ½ä»ªè¡¨æ¿**: å¯è§†åŒ–ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
- **æ™ºèƒ½å‘Šè­¦**: å¤šæ¸ é“å‘Šè­¦é€šçŸ¥ç³»ç»Ÿ

### æ¶æ„ä¼˜åŒ–
- **è®¾è®¡æ¨¡å¼**: ä¾èµ–æ³¨å…¥ã€è§‚å¯Ÿè€…æ¨¡å¼ã€å·¥å‚æ¨¡å¼
- **æ¨¡å—åŒ–é‡æ„**: å•ä¸€èŒè´£åŸåˆ™ï¼Œé™ä½è€¦åˆåº¦
- **å®¹é”™æœºåˆ¶**: é‡è¯•ç­–ç•¥ã€ç†”æ–­é™çº§ã€å¥åº·æ£€æŸ¥
- **é…ç½®ç®¡ç†**: é›†ä¸­å¼é…ç½®ç®¡ç†ï¼Œæ”¯æŒçƒ­æ›´æ–°

### éƒ¨ç½²ä¼˜åŒ–
- **å®¹å™¨åŒ–éƒ¨ç½²**: Docker+Docker Composeå®Œæ•´æ–¹æ¡ˆ
- **è´Ÿè½½å‡è¡¡**: å¤šå®ä¾‹è´Ÿè½½å‡è¡¡é…ç½®
- **è‡ªåŠ¨æ‰©å±•**: åŸºäºCPU/å†…å­˜çš„è‡ªåŠ¨æ‰©å±•
- **å¥åº·æ£€æŸ¥**: å¤šå±‚æ¬¡å¥åº·æ£€æŸ¥å’Œè‡ªæ„ˆæœºåˆ¶

### å¿«é€Ÿå¼€å§‹ (ç¬¬äºŒé˜¶æ®µ)
```bash
# ä½¿ç”¨Dockerå¿«é€Ÿéƒ¨ç½²
docker-compose -f docker-compose.stage2.yml up -d

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python scripts/performance_test_runner.py

# æŸ¥çœ‹ç›‘æ§ä»ªè¡¨æ¿
open http://localhost:3000
```

### é…ç½®æ–‡ä»¶
- `stage2_optimization_config.yml` - ä¼˜åŒ–é…ç½®
- `docker-compose.stage2.yml` - å®¹å™¨ç¼–æ’
- `Dockerfile.stage2` - ç”Ÿäº§é•œåƒ
- `requirements-stage2.txt` - ä¼˜åŒ–ä¾èµ–
"""

        # åœ¨é€‚å½“ä½ç½®æ’å…¥æ–°å†…å®¹
        if "## æŠ€æœ¯æ ˆ" in content:
            insert_point = content.find("## æŠ€æœ¯æ ˆ")
            new_content = content[:insert_point] + stage2_content + "\n" + content[insert_point:]

            # å¤‡ä»½åŸæ–‡ä»¶
            backup_path = readme_path.with_suffix('.md.backup')
            shutil.copy2(readme_path, backup_path)

            # å†™å…¥æ›´æ–°å†…å®¹
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(new_content)

            self.log_cleanup("update", readme_path, "æ·»åŠ ç¬¬äºŒé˜¶æ®µä¼˜åŒ–å†…å®¹")
            return True

        return False

    def clean_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        temp_files = self.find_temp_files()

        for file_path in temp_files:
            try:
                if file_path.is_file():
                    file_path.unlink()
                    self.log_cleanup("delete", file_path, "ä¸´æ—¶æ–‡ä»¶")
                elif file_path.is_dir():
                    shutil.rmtree(file_path)
                    self.log_cleanup("delete", file_path, "ä¸´æ—¶ç›®å½•")
            except Exception as e:
                self.logger.error(f"æ— æ³•åˆ é™¤ {file_path}: {e}")

    def clean_outdated_docs(self):
        """æ¸…ç†è¿‡æ—¶æ–‡æ¡£"""
        outdated_docs = self.find_outdated_docs()

        for doc_path in outdated_docs:
            if doc_path.exists():
                try:
                    # ç§»åŠ¨åˆ°å¤‡ä»½ç›®å½•
                    backup_dir = self.project_root / "docs" / "archived"
                    backup_dir.mkdir(exist_ok=True)

                    backup_path = backup_dir / f"{doc_path.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}{doc_path.suffix}"
                    shutil.move(str(doc_path), str(backup_path))

                    self.log_cleanup("archive", doc_path, f"ç§»åŠ¨åˆ° {backup_path}")
                except Exception as e:
                    self.logger.error(f"æ— æ³•å½’æ¡£ {doc_path}: {e}")

    def generate_cleanup_report(self):
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        report_path = self.project_root / "cleanup_report.md"

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# StockSchool é¡¹ç›®æ¸…ç†æŠ¥å‘Š\n\n")
            f.write(f"æ¸…ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("## æ¸…ç†æ“ä½œè®°å½•\n\n")

            for entry in self.cleanup_log:
                f.write(f"- **{entry['action']}**: `{entry['path']}` - {entry['description']}\n")

            f.write("\n## å»ºè®®\n\n")
            f.write("- å®šæœŸæ£€æŸ¥ä¸´æ—¶æ–‡ä»¶å’Œè¿‡æ—¶æ–‡æ¡£\n")
            f.write("- ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç®¡ç†é‡è¦æ–‡æ¡£å˜æ›´\n")
            f.write("- å»ºç«‹æ–‡æ¡£å½’æ¡£ç­–ç•¥\n")

        self.log_cleanup("create", report_path, "æ¸…ç†æŠ¥å‘Š")

    def run_cleanup(self):
        """æ‰§è¡Œå®Œæ•´æ¸…ç†æµç¨‹"""
        print("ğŸ§¹ å¼€å§‹æ¸…ç†StockSchoolé¡¹ç›®...")

        # 1. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        print("ğŸ“ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        self.clean_temp_files()

        # 2. æ¸…ç†è¿‡æ—¶æ–‡æ¡£
        print("ğŸ“„ å½’æ¡£è¿‡æ—¶æ–‡æ¡£...")
        self.clean_outdated_docs()

        # 3. æ›´æ–°README
        print("ğŸ“ æ›´æ–°README.md...")
        self.update_readme()

        # 4. ç”Ÿæˆæ¸…ç†æŠ¥å‘Š
        print("ğŸ“Š ç”Ÿæˆæ¸…ç†æŠ¥å‘Š...")
        self.generate_cleanup_report()

        print("âœ… æ¸…ç†å®Œæˆï¼")
        print(f"ğŸ“‹ å…±æ‰§è¡Œ {len(self.cleanup_log)} é¡¹æ¸…ç†æ“ä½œ")
        print("ğŸ“„ æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: cleanup_report.md")

if __name__ == "__main__":
    project_root = Path(__file__).parent.parent
    cleaner = ProjectCleaner(project_root)
    cleaner.run_cleanup()