"""
AIæœåŠ¡éªŒæ”¶é˜¶æ®µæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯AIæœåŠ¡éªŒæ”¶é˜¶æ®µæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""
import os
import sys
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from src.acceptance.phases.ai_service import AIServicePhase
from src.acceptance.core.models import TestStatus

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_ai_service_phase():
    """æµ‹è¯•AIæœåŠ¡éªŒæ”¶é˜¶æ®µ"""
    logger.info("=== å¼€å§‹æµ‹è¯•AIæœåŠ¡éªŒæ”¶é˜¶æ®µ ===")
    
    try:
        # åˆ›å»ºAIæœåŠ¡éªŒæ”¶é˜¶æ®µå®ä¾‹
        config = {
            'config_file': '.env.acceptance',
            'test_timeout': 300,
            'max_concurrent_tests': 3
        }
        
        ai_service_phase = AIServicePhase(
            phase_name="AIæœåŠ¡éªŒæ”¶æµ‹è¯•",
            config=config
        )
        
        logger.info("AIæœåŠ¡éªŒæ”¶é˜¶æ®µå®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # æ‰§è¡ŒéªŒæ”¶æµ‹è¯•
        logger.info("å¼€å§‹æ‰§è¡ŒAIæœåŠ¡éªŒæ”¶æµ‹è¯•...")
        start_time = datetime.now()
        
        results = ai_service_phase.execute()
        
        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()
        
        logger.info(f"AIæœåŠ¡éªŒæ”¶æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {execution_time:.2f}ç§’")
        
        # åˆ†æç»“æœ
        total_tests = len(results)
        passed_tests = sum(1 for r in results if r.status == TestStatus.PASSED)
        failed_tests = sum(1 for r in results if r.status == TestStatus.FAILED)
        skipped_tests = sum(1 for r in results if r.status == TestStatus.SKIPPED)
        
        logger.info(f"æµ‹è¯•ç»“æœç»Ÿè®¡:")
        logger.info(f"  æ€»æµ‹è¯•æ•°: {total_tests}")
        logger.info(f"  é€šè¿‡æµ‹è¯•: {passed_tests}")
        logger.info(f"  å¤±è´¥æµ‹è¯•: {failed_tests}")
        logger.info(f"  è·³è¿‡æµ‹è¯•: {skipped_tests}")
        logger.info(f"  æˆåŠŸç‡: {passed_tests/total_tests:.1%}" if total_tests > 0 else "  æˆåŠŸç‡: N/A")
        
        # æ‰“å°è¯¦ç»†ç»“æœ
        logger.info("\n=== è¯¦ç»†æµ‹è¯•ç»“æœ ===")
        for result in results:
            status_icon = {
                TestStatus.PASSED: "âœ…",
                TestStatus.FAILED: "âŒ", 
                TestStatus.SKIPPED: "â­ï¸"
            }.get(result.status, "â“")
            
            logger.info(f"{status_icon} {result.test_name}: {result.status.value} ({result.execution_time:.3f}s)")
            
            if result.error_message:
                logger.info(f"    é”™è¯¯: {result.error_message}")
            
            if result.details:
                # åªæ˜¾ç¤ºå…³é”®ä¿¡æ¯ï¼Œé¿å…æ—¥å¿—è¿‡é•¿
                key_details = {}
                for key, value in result.details.items():
                    if key in ['training_status', 'models_count', 'successful_count', 'performance_score', 'functionality_score']:
                        key_details[key] = value
                if key_details:
                    logger.info(f"    è¯¦æƒ…: {key_details}")
        
        # æ¸…ç†èµ„æº
        ai_service_phase._cleanup_resources()
        
        return failed_tests == 0
        
    except Exception as e:
        logger.error(f"AIæœåŠ¡éªŒæ”¶é˜¶æ®µæµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("StockSchool AIæœåŠ¡éªŒæ”¶é˜¶æ®µæµ‹è¯•")
    
    success = test_ai_service_phase()
    
    if success:
        logger.info("ğŸ‰ AIæœåŠ¡éªŒæ”¶é˜¶æ®µæµ‹è¯•æˆåŠŸï¼")
        sys.exit(0)
    else:
        logger.error("ğŸ’¥ AIæœåŠ¡éªŒæ”¶é˜¶æ®µæµ‹è¯•å¤±è´¥ï¼")
        sys.exit(1)


if __name__ == '__main__':
    main()