#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹è§£é‡Šå™¨ç”¨æˆ·ç•Œé¢

ä½¿ç”¨Streamlitåˆ›å»ºç®€å•çš„Webç•Œé¢ï¼Œç”¨äºæµ‹è¯•å’Œæ¼”ç¤ºæ¨¡å‹è§£é‡ŠåŠŸèƒ½
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import os
from typing import List, Dict, Any
import joblib

from src.strategy.model_explainer import ModelExplainer
from src.utils.config_loader import config

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="StockSchool æ¨¡å‹è§£é‡Šå™¨",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    """ä¸»ç•Œé¢"""
    st.title("ğŸ“Š StockSchool æ¨¡å‹è§£é‡Šå™¨")
    st.markdown("""
    è¿™æ˜¯ä¸€ä¸ªç”¨äºè§£é‡Šæœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹ç»“æœçš„å·¥å…·ã€‚
    æ”¯æŒå¤šç§è§£é‡Šæ–¹æ³•ï¼ŒåŒ…æ‹¬SHAPå€¼ã€ç‰¹å¾é‡è¦æ€§ç­‰ã€‚
    """)
    
    # ä¾§è¾¹æ 
    st.sidebar.header("âš™ï¸ é…ç½®")
    
    # é€‰æ‹©åŠŸèƒ½
    feature = st.sidebar.radio(
        "é€‰æ‹©åŠŸèƒ½",
        ["æ¨¡å‹ä¿¡æ¯", "ç‰¹å¾é‡è¦æ€§", "é¢„æµ‹è§£é‡Š", "æ‰¹é‡è§£é‡Š", "æ¨¡å‹å¯¹æ¯”"]
    )
    
    if feature == "æ¨¡å‹ä¿¡æ¯":
        model_info_page()
    elif feature == "ç‰¹å¾é‡è¦æ€§":
        feature_importance_page()
    elif feature == "é¢„æµ‹è§£é‡Š":
        prediction_explanation_page()
    elif feature == "æ‰¹é‡è§£é‡Š":
        batch_explanation_page()
    elif feature == "æ¨¡å‹å¯¹æ¯”":
        model_comparison_page()

def model_info_page():
    """æ¨¡å‹ä¿¡æ¯é¡µé¢"""
    st.header("ğŸ” æ¨¡å‹ä¿¡æ¯")
    
    # ä¸Šä¼ æ¨¡å‹æ–‡ä»¶
    model_file = st.file_uploader("ä¸Šä¼ æ¨¡å‹æ–‡ä»¶", type=['pkl', 'joblib'])
    
    if model_file is not None:
        try:
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_path = f"temp_model_{model_file.name}"
            with open(temp_path, "wb") as f:
                f.write(model_file.getbuffer())
            
            # åŠ è½½æ¨¡å‹
            model = joblib.load(temp_path)
            
            # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            st.subheader("æ¨¡å‹åŸºæœ¬ä¿¡æ¯")
            model_info = {
                "æ¨¡å‹ç±»å‹": type(model).__name__,
                "æ¨¡å‹æ¨¡å—": type(model).__module__,
                "æ”¯æŒé¢„æµ‹": hasattr(model, 'predict'),
                "æ”¯æŒç‰¹å¾é‡è¦æ€§": hasattr(model, 'feature_importances_'),
                "æ”¯æŒç³»æ•°": hasattr(model, 'coef_')
            }
            
            col1, col2 = st.columns(2)
            with col1:
                st.json(model_info)
            
            with col2:
                st.info("ğŸ’¡ æç¤ºï¼šç¡®ä¿ä¸Šä¼ çš„æ¨¡å‹æ–‡ä»¶æ ¼å¼æ­£ç¡®")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.remove(temp_path)
            
        except Exception as e:
            st.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")

def feature_importance_page():
    """ç‰¹å¾é‡è¦æ€§é¡µé¢"""
    st.header("ğŸ“ˆ ç‰¹å¾é‡è¦æ€§åˆ†æ")
    
    # ä¸Šä¼ æ¨¡å‹æ–‡ä»¶
    model_file = st.file_uploader("ä¸Šä¼ æ¨¡å‹æ–‡ä»¶", type=['pkl', 'joblib'], key="fi_model")
    
    if model_file is not None:
        try:
            # ä¸Šä¼ æ•°æ®æ–‡ä»¶
            data_file = st.file_uploader("ä¸Šä¼ æ•°æ®æ–‡ä»¶ (CSV)", type=['csv'], key="fi_data")
            
            if data_file is not None:
                # è¯»å–æ•°æ®
                df = pd.read_csv(data_file)
                st.subheader("æ•°æ®é¢„è§ˆ")
                st.dataframe(df.head())
                
                # é€‰æ‹©ç‰¹å¾åˆ—
                feature_columns = st.multiselect(
                    "é€‰æ‹©ç‰¹å¾åˆ—", 
                    df.columns.tolist(),
                    default=df.columns.tolist()[:5] if len(df.columns) >= 5 else df.columns.tolist()
                )
                
                if feature_columns:
                    # é€‰æ‹©ç›®æ ‡åˆ—ï¼ˆå¯é€‰ï¼‰
                    target_column = st.selectbox(
                        "é€‰æ‹©ç›®æ ‡åˆ—ï¼ˆå¯é€‰ï¼‰", 
                        ["æ— "] + [col for col in df.columns if col not in feature_columns]
                    )
                    
                    # é€‰æ‹©è§£é‡Šæ–¹æ³•
                    method = st.selectbox(
                        "é€‰æ‹©è§£é‡Šæ–¹æ³•", 
                        ["default", "permutation", "shap"],
                        format_func=lambda x: {
                            "default": "é»˜è®¤é‡è¦æ€§",
                            "permutation": "æ’åˆ—é‡è¦æ€§",
                            "shap": "SHAPå€¼"
                        }[x]
                    )
                    
                    if st.button("è®¡ç®—ç‰¹å¾é‡è¦æ€§", type="primary"):
                        with st.spinner("æ­£åœ¨è®¡ç®—ç‰¹å¾é‡è¦æ€§..."):
                            try:
                                # ä¿å­˜å¹¶åŠ è½½æ¨¡å‹
                                temp_model_path = f"temp_model_{model_file.name}"
                                with open(temp_model_path, "wb") as f:
                                    f.write(model_file.getbuffer())
                                
                                model = joblib.load(temp_model_path)
                                
                                # å‡†å¤‡æ•°æ®
                                X = df[feature_columns]
                                y = df[target_column] if target_column != "æ— " else None
                                
                                # åˆ›å»ºè§£é‡Šå™¨å¹¶è®¡ç®—é‡è¦æ€§
                                explainer = ModelExplainer(model, feature_columns)
                                importance = explainer.calculate_feature_importance(X, y, method=method)
                                
                                # æ˜¾ç¤ºç»“æœ
                                st.subheader("ç‰¹å¾é‡è¦æ€§ç»“æœ")
                                st.dataframe(importance)
                                
                                # å¯è§†åŒ–
                                fig, ax = plt.subplots(figsize=(10, 6))
                                top_features = importance.head(10)
                                bars = ax.barh(range(len(top_features)), top_features['importance'])
                                ax.set_yticks(range(len(top_features)))
                                ax.set_yticklabels(top_features['feature'])
                                ax.set_xlabel('é‡è¦æ€§')
                                ax.set_title(f'ç‰¹å¾é‡è¦æ€§ ({method.upper()}æ–¹æ³•)')
                                ax.invert_yaxis()
                                
                                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                                for i, (bar, importance_val) in enumerate(zip(bars, top_features['importance'])):
                                    ax.text(bar.get_width(), i, f'{importance_val:.4f}', 
                                           va='center', ha='left', fontsize=8)
                                
                                st.pyplot(fig)
                                
                                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                                os.remove(temp_model_path)
                                
                            except Exception as e:
                                st.error(f"è®¡ç®—ç‰¹å¾é‡è¦æ€§å¤±è´¥: {e}")
                
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")

def prediction_explanation_page():
    """é¢„æµ‹è§£é‡Šé¡µé¢"""
    st.header("ğŸ¯ é¢„æµ‹ç»“æœè§£é‡Š")
    
    # ä¸Šä¼ æ¨¡å‹æ–‡ä»¶
    model_file = st.file_uploader("ä¸Šä¼ æ¨¡å‹æ–‡ä»¶", type=['pkl', 'joblib'], key="pe_model")
    
    if model_file is not None:
        try:
            # ä¸Šä¼ æ•°æ®æ–‡ä»¶
            data_file = st.file_uploader("ä¸Šä¼ æ•°æ®æ–‡ä»¶ (CSV)", type=['csv'], key="pe_data")
            
            if data_file is not None:
                # è¯»å–æ•°æ®
                df = pd.read_csv(data_file)
                st.subheader("æ•°æ®é¢„è§ˆ")
                st.dataframe(df.head())
                
                # é€‰æ‹©ç‰¹å¾åˆ—
                feature_columns = st.multiselect(
                    "é€‰æ‹©ç‰¹å¾åˆ—", 
                    df.columns.tolist(),
                    default=df.columns.tolist()[:5] if len(df.columns) >= 5 else df.columns.tolist()
                )
                
                if feature_columns:
                    # é€‰æ‹©æ ·æœ¬ç´¢å¼•
                    sample_idx = st.number_input(
                        "é€‰æ‹©æ ·æœ¬ç´¢å¼•", 
                        min_value=0, 
                        max_value=len(df)-1, 
                        value=0
                    )
                    
                    if st.button("è§£é‡Šé¢„æµ‹ç»“æœ", type="primary"):
                        with st.spinner("æ­£åœ¨è§£é‡Šé¢„æµ‹ç»“æœ..."):
                            try:
                                # ä¿å­˜å¹¶åŠ è½½æ¨¡å‹
                                temp_model_path = f"temp_model_{model_file.name}"
                                with open(temp_model_path, "wb") as f:
                                    f.write(model_file.getbuffer())
                                
                                model = joblib.load(temp_model_path)
                                
                                # å‡†å¤‡æ•°æ®
                                X = df[feature_columns]
                                
                                # åˆ›å»ºè§£é‡Šå™¨å¹¶è§£é‡Šé¢„æµ‹
                                explainer = ModelExplainer(model, feature_columns)
                                explanation = explainer.explain_prediction(X, sample_idx)
                                
                                # æ˜¾ç¤ºç»“æœ
                                st.subheader("é¢„æµ‹è§£é‡Šç»“æœ")
                                
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.metric("é¢„æµ‹å€¼", f"{explanation.get('prediction', 'N/A'):.4f}")
                                    st.metric("åŸºç¡€å€¼", f"{explanation.get('base_value', 0):.4f}")
                                    st.write(f"æ¨¡å‹ç±»å‹: {explanation.get('model_type', 'N/A')}")
                                
                                with col2:
                                    st.write("ç‰¹å¾å€¼:")
                                    feature_values = explanation.get('feature_values', [])
                                    for i, (feature, value) in enumerate(zip(feature_columns, feature_values)):
                                        st.write(f"**{feature}**: {value:.4f}")
                                
                                # SHAPå€¼å¯è§†åŒ–
                                st.subheader("SHAPå€¼åˆ†æ")
                                shap_values = explanation.get('shap_values', [])
                                if shap_values:
                                    fig, ax = plt.subplots(figsize=(10, 8))
                                    
                                    y_pos = np.arange(len(feature_columns))
                                    colors = ['red' if val < 0 else 'blue' for val in shap_values]
                                    bars = ax.barh(y_pos, shap_values, color=colors, alpha=0.7)
                                    
                                    ax.set_yticks(y_pos)
                                    ax.set_yticklabels([f"{feat}\n({val:.4f})" for feat, val in zip(feature_columns, feature_values)])
                                    ax.set_xlabel('SHAPå€¼')
                                    ax.set_title(f'é¢„æµ‹è§£é‡Š - æ ·æœ¬ {sample_idx}')
                                    ax.invert_yaxis()
                                    ax.axvline(x=0, color='black', linestyle='-', alpha=0.3)
                                    
                                    st.pyplot(fig)
                                
                                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                                os.remove(temp_model_path)
                                
                            except Exception as e:
                                st.error(f"è§£é‡Šé¢„æµ‹ç»“æœå¤±è´¥: {e}")
                
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")

def batch_explanation_page():
    """æ‰¹é‡è§£é‡Šé¡µé¢"""
    st.header("ğŸ”„ æ‰¹é‡é¢„æµ‹è§£é‡Š")
    st.info("æ­¤åŠŸèƒ½æ”¯æŒå¯¹å¤šä¸ªæ ·æœ¬è¿›è¡Œæ‰¹é‡è§£é‡Šåˆ†æ")
    
    # ä¸Šä¼ æ¨¡å‹æ–‡ä»¶
    model_file = st.file_uploader("ä¸Šä¼ æ¨¡å‹æ–‡ä»¶", type=['pkl', 'joblib'], key="be_model")
    
    if model_file is not None:
        try:
            # ä¸Šä¼ æ•°æ®æ–‡ä»¶
            data_file = st.file_uploader("ä¸Šä¼ æ•°æ®æ–‡ä»¶ (CSV)", type=['csv'], key="be_data")
            
            if data_file is not None:
                # è¯»å–æ•°æ®
                df = pd.read_csv(data_file)
                st.subheader("æ•°æ®é¢„è§ˆ")
                st.dataframe(df.head())
                
                # é€‰æ‹©ç‰¹å¾åˆ—
                feature_columns = st.multiselect(
                    "é€‰æ‹©ç‰¹å¾åˆ—", 
                    df.columns.tolist(),
                    default=df.columns.tolist()[:5] if len(df.columns) >= 5 else df.columns.tolist()
                )
                
                if feature_columns:
                    # é€‰æ‹©æ ·æœ¬èŒƒå›´
                    col1, col2 = st.columns(2)
                    with col1:
                        start_idx = st.number_input(
                            "èµ·å§‹æ ·æœ¬ç´¢å¼•", 
                            min_value=0, 
                            max_value=len(df)-1, 
                            value=0
                        )
                    with col2:
                        end_idx = st.number_input(
                            "ç»“æŸæ ·æœ¬ç´¢å¼•", 
                            min_value=start_idx+1, 
                            max_value=len(df), 
                            value=min(start_idx+10, len(df))
                        )
                    
                    if st.button("æ‰¹é‡è§£é‡Š", type="primary"):
                        with st.spinner("æ­£åœ¨æ‰¹é‡è§£é‡Šé¢„æµ‹ç»“æœ..."):
                            try:
                                # ä¿å­˜å¹¶åŠ è½½æ¨¡å‹
                                temp_model_path = f"temp_model_{model_file.name}"
                                with open(temp_model_path, "wb") as f:
                                    f.write(model_file.getbuffer())
                                
                                model = joblib.load(temp_model_path)
                                
                                # å‡†å¤‡æ•°æ®
                                X = df[feature_columns].iloc[start_idx:end_idx]
                                
                                # åˆ›å»ºè§£é‡Šå™¨å¹¶æ‰¹é‡è§£é‡Š
                                explainer = ModelExplainer(model, feature_columns)
                                
                                explanations = []
                                for i in range(len(X)):
                                    explanation = explainer.explain_prediction(X, i)
                                    explanations.append(explanation)
                                
                                # æ˜¾ç¤ºç»“æœ
                                st.subheader(f"æ‰¹é‡è§£é‡Šç»“æœ (æ ·æœ¬ {start_idx} åˆ° {end_idx-1})")
                                
                                # æ±‡æ€»ç»Ÿè®¡
                                shap_values_list = [exp.get('shap_values', []) for exp in explanations]
                                if shap_values_list and shap_values_list[0]:
                                    avg_shap_values = np.mean(shap_values_list, axis=0)
                                    
                                    st.subheader("å¹³å‡SHAPå€¼")
                                    fig, ax = plt.subplots(figsize=(10, 6))
                                    bars = ax.barh(range(len(feature_columns)), avg_shap_values)
                                    ax.set_yticks(range(len(feature_columns)))
                                    ax.set_yticklabels(feature_columns)
                                    ax.set_xlabel('å¹³å‡SHAPå€¼')
                                    ax.set_title('æ‰¹é‡æ ·æœ¬å¹³å‡ç‰¹å¾è´¡çŒ®')
                                    ax.invert_yaxis()
                                    ax.axvline(x=0, color='black', linestyle='-', alpha=0.3)
                                    st.pyplot(fig)
                                
                                # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                                st.subheader("è¯¦ç»†è§£é‡Š")
                                for i, explanation in enumerate(explanations):
                                    with st.expander(f"æ ·æœ¬ {start_idx + i} - é¢„æµ‹å€¼: {explanation.get('prediction', 'N/A'):.4f}"):
                                        col1, col2 = st.columns(2)
                                        with col1:
                                            st.write("SHAPå€¼:")
                                            shap_values = explanation.get('shap_values', [])
                                            for feature, shap_val in zip(feature_columns, shap_values):
                                                st.write(f"**{feature}**: {shap_val:.4f}")
                                        with col2:
                                            st.write("ç‰¹å¾å€¼:")
                                            feature_values = explanation.get('feature_values', [])
                                            for feature, value in zip(feature_columns, feature_values):
                                                st.write(f"**{feature}**: {value:.4f}")
                                
                                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                                os.remove(temp_model_path)
                                
                            except Exception as e:
                                st.error(f"æ‰¹é‡è§£é‡Šå¤±è´¥: {e}")
                
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")

def model_comparison_page():
    """æ¨¡å‹å¯¹æ¯”é¡µé¢"""
    st.header("âš–ï¸ æ¨¡å‹å¯¹æ¯”åˆ†æ")
    st.info("æ­¤åŠŸèƒ½æ”¯æŒå¯¹æ¯”å¤šä¸ªæ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§å’Œé¢„æµ‹è§£é‡Š")
    
    # ä¸Šä¼ å¤šä¸ªæ¨¡å‹æ–‡ä»¶
    st.subheader("ä¸Šä¼ æ¨¡å‹æ–‡ä»¶")
    model_files = st.file_uploader(
        "ä¸Šä¼ å¤šä¸ªæ¨¡å‹æ–‡ä»¶", 
        type=['pkl', 'joblib'], 
        accept_multiple_files=True,
        key="mc_models"
    )
    
    if len(model_files) >= 2:
        try:
            # ä¸Šä¼ æ•°æ®æ–‡ä»¶
            data_file = st.file_uploader("ä¸Šä¼ æ•°æ®æ–‡ä»¶ (CSV)", type=['csv'], key="mc_data")
            
            if data_file is not None:
                # è¯»å–æ•°æ®
                df = pd.read_csv(data_file)
                st.subheader("æ•°æ®é¢„è§ˆ")
                st.dataframe(df.head())
                
                # é€‰æ‹©ç‰¹å¾åˆ—
                feature_columns = st.multiselect(
                    "é€‰æ‹©ç‰¹å¾åˆ—", 
                    df.columns.tolist(),
                    default=df.columns.tolist()[:5] if len(df.columns) >= 5 else df.columns.tolist()
                )
                
                if feature_columns:
                    # é€‰æ‹©è§£é‡Šæ–¹æ³•
                    method = st.selectbox(
                        "é€‰æ‹©è§£é‡Šæ–¹æ³•", 
                        ["default", "permutation", "shap"],
                        format_func=lambda x: {
                            "default": "é»˜è®¤é‡è¦æ€§",
                            "permutation": "æ’åˆ—é‡è¦æ€§",
                            "shap": "SHAPå€¼"
                        }[x]
                    )
                    
                    # é€‰æ‹©æ ·æœ¬ç´¢å¼•
                    sample_idx = st.number_input(
                        "é€‰æ‹©æ ·æœ¬ç´¢å¼•", 
                        min_value=0, 
                        max_value=len(df)-1, 
                        value=0
                    )
                    
                    if st.button("å¯¹æ¯”åˆ†æ", type="primary"):
                        with st.spinner("æ­£åœ¨è¿›è¡Œæ¨¡å‹å¯¹æ¯”åˆ†æ..."):
                            try:
                                # åŠ è½½æ‰€æœ‰æ¨¡å‹
                                models = []
                                model_names = []
                                
                                for i, model_file in enumerate(model_files):
                                    temp_model_path = f"temp_model_{i}_{model_file.name}"
                                    with open(temp_model_path, "wb") as f:
                                        f.write(model_file.getbuffer())
                                    
                                    model = joblib.load(temp_model_path)
                                    models.append(model)
                                    model_names.append(f"æ¨¡å‹ {i+1} ({type(model).__name__})")
                                    
                                # å‡†å¤‡æ•°æ®
                                X = df[feature_columns]
                                
                                # å¯¹æ¯”ç‰¹å¾é‡è¦æ€§
                                st.subheader("ç‰¹å¾é‡è¦æ€§å¯¹æ¯”")
                                
                                importance_data = []
                                for model, model_name in zip(models, model_names):
                                    explainer = ModelExplainer(model, feature_columns)
                                    importance = explainer.calculate_feature_importance(X, method=method)
                                    importance['model'] = model_name
                                    importance_data.append(importance)
                                
                                # åˆå¹¶æ•°æ®
                                combined_importance = pd.concat(importance_data, ignore_index=True)
                                
                                # å¯è§†åŒ–å¯¹æ¯”
                                fig, ax = plt.subplots(figsize=(12, 8))
                                
                                # åªæ˜¾ç¤ºå‰10ä¸ªç‰¹å¾
                                top_features = importance_data[0].head(10)['feature'].tolist()
                                
                                for model_name in model_names:
                                    model_importance = combined_importance[combined_importance['model'] == model_name]
                                    model_importance = model_importance[model_importance['feature'].isin(top_features)]
                                    model_importance = model_importance.set_index('feature').reindex(top_features)
                                    ax.plot(range(len(top_features)), model_importance['importance'], 
                                           marker='o', label=model_name, linewidth=2)
                                
                                ax.set_xticks(range(len(top_features)))
                                ax.set_xticklabels(top_features, rotation=45)
                                ax.set_xlabel('ç‰¹å¾')
                                ax.set_ylabel('é‡è¦æ€§')
                                ax.set_title(f'æ¨¡å‹ç‰¹å¾é‡è¦æ€§å¯¹æ¯” ({method.upper()}æ–¹æ³•)')
                                ax.legend()
                                ax.grid(True, alpha=0.3)
                                
                                st.pyplot(fig)
                                
                                # å¯¹æ¯”é¢„æµ‹è§£é‡Š
                                st.subheader("é¢„æµ‹è§£é‡Šå¯¹æ¯”")
                                
                                explanation_data = []
                                for model, model_name in zip(models, model_names):
                                    explainer = ModelExplainer(model, feature_columns)
                                    explanation = explainer.explain_prediction(X, sample_idx)
                                    explanation['model'] = model_name
                                    explanation_data.append(explanation)
                                
                                # æ˜¾ç¤ºé¢„æµ‹å€¼å¯¹æ¯”
                                pred_values = [exp['prediction'] for exp in explanation_data]
                                pred_df = pd.DataFrame({
                                    'æ¨¡å‹': model_names,
                                    'é¢„æµ‹å€¼': pred_values
                                })
                                
                                st.dataframe(pred_df)
                                
                                # å¯è§†åŒ–é¢„æµ‹å€¼å¯¹æ¯”
                                fig2, ax2 = plt.subplots(figsize=(10, 6))
                                bars = ax2.bar(model_names, pred_values, color=['skyblue', 'lightcoral', 'lightgreen', 'gold'][:len(model_names)])
                                ax2.set_ylabel('é¢„æµ‹å€¼')
                                ax2.set_title(f'ä¸åŒæ¨¡å‹é¢„æµ‹å€¼å¯¹æ¯” (æ ·æœ¬ {sample_idx})')
                                
                                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                                for bar, value in zip(bars, pred_values):
                                    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                                            f'{value:.4f}', ha='center', va='bottom')
                                
                                plt.xticks(rotation=45)
                                st.pyplot(fig2)
                                
                                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                                for i in range(len(model_files)):
                                    temp_model_path = f"temp_model_{i}_{model_files[i].name}"
                                    if os.path.exists(temp_model_path):
                                        os.remove(temp_model_path)
                                
                            except Exception as e:
                                st.error(f"æ¨¡å‹å¯¹æ¯”åˆ†æå¤±è´¥: {e}")
                
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")
    else:
        st.info("è¯·è‡³å°‘ä¸Šä¼ ä¸¤ä¸ªæ¨¡å‹æ–‡ä»¶è¿›è¡Œå¯¹æ¯”åˆ†æ")

if __name__ == "__main__":
    main()
