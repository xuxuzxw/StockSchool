import os
import sys
import pandas as pd
import tushare as ts
from loguru import logger
from sqlalchemy import create_engine, text
from datetime import datetime, timedelta
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from src.config.unified_config import config
from src.utils.db import get_db_engine
from src.utils.retry import idempotent_retry

class TushareSynchronizer:
    def __init__(self):
        """åˆå§‹åŒ–TushareåŒæ­¥å™¨"""
        token = os.getenv("TUSHARE_TOKEN")
        if not token:
            raise ValueError("TUSHARE_TOKENç¯å¢ƒå˜é‡æœªè®¾ç½®")
        
        self.pro = ts.pro_api(token)
        self.engine = get_db_engine()
        self.config = config
        print("âœ… TushareåŒæ­¥å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    @idempotent_retry()
    def get_last_trade_date(self):
        """è·å–æ•°æ®åº“ä¸­æœ€åä¸€ä¸ªäº¤æ˜“æ—¥æœŸ"""
        try:
            with self.engine.connect() as conn:
                result = conn.execute(text("SELECT max(trade_date) FROM stock_daily")).scalar()
            if result:
                return result.strftime('%Y%m%d')
            else:
                # å¦‚æœè¡¨ä¸­æ²¡æœ‰æ•°æ®ï¼Œè¿”å›ä¸€å¹´å‰çš„ä»Šå¤©
                return (datetime.now() - timedelta(days=365)).strftime('%Y%m%d')
        except Exception as e:
            print(f"è·å–æœ€åäº¤æ˜“æ—¥æœŸå¤±è´¥: {e}")
            return '20100101'
    
    @idempotent_retry()
    def sync_stock_basic(self):
        """åŒæ­¥è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        logger.info("å¼€å§‹æ‰§è¡Œ sync_stock_basic å‡½æ•°")
        print("å¼€å§‹åŒæ­¥è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
        try:
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            df = self.pro.stock_basic(
                exchange='', 
                list_status='L', 
                fields='ts_code,symbol,name,area,industry,market,list_status,list_date'
            )
            
            if df.empty:
                print("âš ï¸ æœªè·å–åˆ°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
                return
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
            with self.engine.connect() as conn:
                conn.execute(text("""
                    CREATE TABLE IF NOT EXISTS stock_basic (
                        ts_code VARCHAR(10) PRIMARY KEY,
                        symbol VARCHAR(10),
                        name VARCHAR(50),
                        area VARCHAR(20),
                        industry VARCHAR(50),
                        market VARCHAR(10),
                        list_status VARCHAR(2),
                        list_date DATE
                    )
                """))
                conn.commit()
            
            # æ¸…ç©ºè¡¨å¹¶æ’å…¥æ–°æ•°æ®
            with self.engine.connect() as conn:
                conn.execute(text("DELETE FROM stock_basic"))
                conn.commit()
            
            df.to_sql('stock_basic', self.engine, if_exists='append', index=False)
            print(f"âœ… æˆåŠŸåŒæ­¥ {len(df)} åªè‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯")
            logger.info("sync_stock_basic å‡½æ•°æ‰§è¡ŒæˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ åŒæ­¥è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
            raise
    
    @idempotent_retry()
    def sync_trade_calendar(self, start_year=None):
        """åŒæ­¥äº¤æ˜“æ—¥å†"""
        print("å¼€å§‹åŒæ­¥äº¤æ˜“æ—¥å†...")
        try:
            if start_year is None:
                start_year = self.config.get('data_sync_params.start_year', 2020)
            current_year = datetime.now().year
            start_date = f'{start_year}0101'
            end_date = f'{current_year + 1}1231'
            
            df = self.pro.trade_cal(
                exchange='', 
                start_date=start_date, 
                end_date=end_date
            )
            
            if df.empty:
                print("âš ï¸ æœªè·å–åˆ°äº¤æ˜“æ—¥å†æ•°æ®")
                return

            # è¿‡æ»¤æ‰æœªæ¥æ—¥æœŸ
            today = datetime.now().strftime('%Y%m%d')
            df = df[df.cal_date <= today]
            
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
            with self.engine.connect() as conn:
                conn.execute(text("""
                    CREATE TABLE IF NOT EXISTS trade_calendar (
                        exchange VARCHAR(10),
                        cal_date DATE,
                        is_open INTEGER,
                        pretrade_date DATE,
                        PRIMARY KEY (exchange, cal_date)
                    )
                """))
                conn.commit()
            
            # é€æ¡æ’å…¥æ•°æ®åº“ï¼Œé¿å…å‚æ•°è¿‡å¤šé”™è¯¯
            total_records = len(df)
            
            with self.engine.connect() as conn:
                # å…ˆæ¸…ç©ºè¡¨
                conn.execute(text("DELETE FROM trade_calendar"))
                conn.commit()
                
                # é€æ¡æ’å…¥ï¼ˆåªæ’å…¥è¡¨ä¸­å­˜åœ¨çš„åˆ—ï¼‰
                for i, row in df.iterrows():
                    conn.execute(text("""
                        INSERT INTO trade_calendar (cal_date, is_open, pretrade_date)
                        VALUES (:cal_date, :is_open, :pretrade_date)
                    """), {
                        'cal_date': row['cal_date'],
                        'is_open': row['is_open'],
                        'pretrade_date': row['pretrade_date']
                    })
                    progress_interval = config.get('data_sync_params.progress_interval', 100)
                    if (i + 1) % progress_interval == 0:
                        print(f"å·²æ’å…¥ {i + 1}/{total_records} æ¡è®°å½•")
                
                conn.commit()
            
            print(f"âœ… æˆåŠŸåŒæ­¥ {total_records} æ¡äº¤æ˜“æ—¥å†è®°å½•")
            
        except Exception as e:
            print(f"âŒ åŒæ­¥äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
            raise
    
    @idempotent_retry()
    def update_daily_data(self, max_days=None):
        """æ›´æ–°æ—¥çº¿æ•°æ®"""
        print("å¼€å§‹æ›´æ–°æ—¥çº¿æ•°æ®...")
        try:
            # è·å–æœ€åäº¤æ˜“æ—¥æœŸ
            last_date = self.get_last_trade_date()
            print(f"æ•°æ®åº“ä¸­æœ€åäº¤æ˜“æ—¥æœŸ: {last_date}")
            
            # è·å–äº¤æ˜“æ—¥å†
            end_date = datetime.now().strftime('%Y%m%d')
            trade_cal = self.pro.trade_cal(exchange='', start_date=last_date, end_date=end_date)
            # è¿‡æ»¤æ‰æœªæ¥æ—¥æœŸ
            trade_cal = trade_cal[trade_cal.cal_date <= end_date]
            trade_dates = trade_cal[trade_cal.is_open == 1]['cal_date'].tolist()
            
            # é™åˆ¶æ›´æ–°å¤©æ•°ï¼Œé¿å…ä¸€æ¬¡æ€§æ›´æ–°å¤ªå¤šæ•°æ®
            if max_days is None:
                max_days = self.config.get('data_sync_params.max_days', 30)
            if len(trade_dates) > max_days:
                trade_dates = trade_dates[:max_days]
                print(f"âš ï¸ é™åˆ¶æ›´æ–°å¤©æ•°ä¸º {max_days} å¤©")
            
            if not trade_dates:
                print("âœ… æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
                return
            
            print(f"éœ€è¦æ›´æ–° {len(trade_dates)} ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®")
            
            success_count = 0
            for i, date in enumerate(trade_dates, 1):
                try:
                    print(f"[{i}/{len(trade_dates)}] æ­£åœ¨åŒæ­¥ {date} çš„æ•°æ®...")
                    
                    # è·å–æ—¥çº¿æ•°æ®
                    df = self.pro.daily(trade_date=date)
                    
                    if df.empty:
                        print(f"âš ï¸ {date} æ— æ•°æ®")
                        continue
                    
                    # é€æ¡æ’å…¥æ•°æ®åº“ï¼Œé¿å…å‚æ•°è¿‡å¤šé”™è¯¯
                    total_records = len(df)
                    
                    with self.engine.connect() as conn:
                        for i, row in df.iterrows():
                             conn.execute(text("""
                                 INSERT INTO stock_daily (ts_code, trade_date, open, high, low, close, pre_close, change, pct_chg, vol, amount)
                                 VALUES (:ts_code, :trade_date, :open, :high, :low, :close, :pre_close, :change, :pct_chg, :vol, :amount)
                                 ON CONFLICT (ts_code, trade_date) DO UPDATE SET
                                     open = EXCLUDED.open,
                                     high = EXCLUDED.high,
                                     low = EXCLUDED.low,
                                     close = EXCLUDED.close,
                                     pre_close = EXCLUDED.pre_close,
                                     change = EXCLUDED.change,
                                     pct_chg = EXCLUDED.pct_chg,
                                     vol = EXCLUDED.vol,
                                     amount = EXCLUDED.amount
                             """), {
                                'ts_code': row['ts_code'],
                                'trade_date': row['trade_date'],
                                'open': row['open'],
                                'high': row['high'],
                                'low': row['low'],
                                'close': row['close'],
                                'pre_close': row['pre_close'],
                                'change': row['change'],
                                'pct_chg': row['pct_chg'],
                                'vol': row['vol'],
                                'amount': row['amount']
                            })
                        conn.commit()
                    
                    success_count += 1
                    print(f"âœ… {date} æ•°æ®åŒæ­¥æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")
                    
                    # APIé™åˆ¶ï¼šæ¯åˆ†é’Ÿæœ€å¤š200æ¬¡è°ƒç”¨ï¼Œæ·»åŠ å»¶æ—¶
                    time.sleep(self.config.get('data_sync_params.sleep_interval', 0.3))
                    
                except Exception as e:
                    print(f"âŒ {date} æ•°æ®åŒæ­¥å¤±è´¥: {e}")
                    continue
            
            print(f"\nğŸ“Š æ—¥çº¿æ•°æ®æ›´æ–°å®Œæˆï¼ŒæˆåŠŸæ›´æ–° {success_count}/{len(trade_dates)} ä¸ªäº¤æ˜“æ—¥")
            
        except Exception as e:
            print(f"âŒ æ›´æ–°æ—¥çº¿æ•°æ®å¤±è´¥: {e}")
            raise
    
    @idempotent_retry()
    def sync_financial_data(self, start_date=None):
        """åŒæ­¥è´¢åŠ¡æ•°æ®ï¼ˆåˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨ï¼‰"""
        print("å¼€å§‹åŒæ­¥è´¢åŠ¡æ•°æ®...")
        try:
            if start_date is None:
                start_date = self.config.get('data_sync_params.financial_data.start_date', '20200101')
            
            batch_size = self.config.get('data_sync_params.financial_data.batch_size', 100)
            sleep_interval = self.config.get('data_sync_params.financial_data.sleep_interval', 0.5)
            
            # è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
            stocks_df = pd.read_sql(
                "SELECT ts_code FROM stock_basic WHERE list_status = 'L'",
                self.engine
            )
            
            total_stocks = len(stocks_df)
            print(f"éœ€è¦åŒæ­¥ {total_stocks} åªè‚¡ç¥¨çš„è´¢åŠ¡æ•°æ®")
            
            # åˆ†æ‰¹å¤„ç†è‚¡ç¥¨
            for i in range(0, total_stocks, batch_size):
                batch_stocks = stocks_df.iloc[i:i+batch_size]
                print(f"æ­£åœ¨å¤„ç†ç¬¬ {i//batch_size + 1} æ‰¹ï¼Œå…± {len(batch_stocks)} åªè‚¡ç¥¨")
                
                for _, stock in batch_stocks.iterrows():
                    ts_code = stock['ts_code']
                    try:
                        # åŒæ­¥åˆ©æ¶¦è¡¨æ•°æ®
                        income_df = self.pro.income(ts_code=ts_code, start_date=start_date)
                        if not income_df.empty:
                            # åŒæ­¥èµ„äº§è´Ÿå€ºè¡¨æ•°æ®
                            balance_df = self.pro.balancesheet(ts_code=ts_code, start_date=start_date)
                            # åŒæ­¥ç°é‡‘æµé‡è¡¨æ•°æ®
                            cashflow_df = self.pro.cashflow(ts_code=ts_code, start_date=start_date)
                            
                            # åˆå¹¶ä¸‰å¤§è´¢åŠ¡æŠ¥è¡¨æ•°æ®
                            self._merge_financial_reports(income_df, balance_df, cashflow_df)
                            
                        time.sleep(sleep_interval)
                        
                    except Exception as e:
                        print(f"âŒ åŒæ­¥ {ts_code} è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
                        continue
                
                print(f"ç¬¬ {i//batch_size + 1} æ‰¹å¤„ç†å®Œæˆ")
            
            print("âœ… è´¢åŠ¡æ•°æ®åŒæ­¥å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ è´¢åŠ¡æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            raise
    
    def _merge_financial_reports(self, income_df, balance_df, cashflow_df):
        """åˆå¹¶ä¸‰å¤§è´¢åŠ¡æŠ¥è¡¨æ•°æ®åˆ°financial_reportsè¡¨"""
        try:
            # æ”¶é›†æ‰€æœ‰åˆå¹¶åçš„æ•°æ®ç”¨äºæ‰¹é‡æ’å…¥
            merged_data_list = []
            
            # ä»¥åˆ©æ¶¦è¡¨ä¸ºåŸºç¡€ï¼Œåˆå¹¶å…¶ä»–æŠ¥è¡¨æ•°æ®
            for _, income_row in income_df.iterrows():
                # æŸ¥æ‰¾å¯¹åº”çš„èµ„äº§è´Ÿå€ºè¡¨å’Œç°é‡‘æµé‡è¡¨æ•°æ®
                balance_row = balance_df[
                    (balance_df['ts_code'] == income_row['ts_code']) & 
                    (balance_df['end_date'] == income_row['end_date'])
                ]
                cashflow_row = cashflow_df[
                    (cashflow_df['ts_code'] == income_row['ts_code']) & 
                    (cashflow_df['end_date'] == income_row['end_date'])
                ]
                
                # æ„å»ºåˆå¹¶æ•°æ®
                merged_data = {
                    'ts_code': income_row['ts_code'],
                    'ann_date': income_row.get('ann_date'),
                    'f_ann_date': income_row.get('f_ann_date'),
                    'end_date': income_row['end_date'],
                    'report_type': income_row.get('report_type'),
                    'comp_type': income_row.get('comp_type'),
                    # åˆ©æ¶¦è¡¨å­—æ®µ
                    'total_revenue': income_row.get('total_revenue'),
                    'revenue': income_row.get('revenue'),
                    'operate_profit': income_row.get('operate_profit'),
                    'total_profit': income_row.get('total_profit'),
                    'n_income': income_row.get('n_income'),
                    'n_income_attr_p': income_row.get('n_income_attr_p'),
                    'basic_eps': income_row.get('basic_eps'),
                    'diluted_eps': income_row.get('diluted_eps'),
                }
                
                # æ·»åŠ èµ„äº§è´Ÿå€ºè¡¨å­—æ®µ
                if not balance_row.empty:
                    balance_data = balance_row.iloc[0]
                    merged_data.update({
                        'total_assets': balance_data.get('total_assets'),
                        'total_liab': balance_data.get('total_liab'),
                        'total_hldr_eqy_inc_min_int': balance_data.get('total_hldr_eqy_inc_min_int'),
                        'total_share': balance_data.get('total_share'),
                    })
                
                # æ·»åŠ ç°é‡‘æµé‡è¡¨å­—æ®µ
                if not cashflow_row.empty:
                    cashflow_data = cashflow_row.iloc[0]
                    merged_data.update({
                        'c_fr_sale_sg': cashflow_data.get('c_fr_sale_sg'),
                        'c_paid_goods_s': cashflow_data.get('c_paid_goods_s'),
                        'n_cashflow_act': cashflow_data.get('n_cashflow_act'),
                        'n_cashflow_inv_act': cashflow_data.get('n_cashflow_inv_act'),
                        'n_cashflow_fin_act': cashflow_data.get('n_cashflow_fin_act'),
                        'c_cash_equ_end_period': cashflow_data.get('c_cash_equ_end_period'),
                    })
                
                # æ·»åŠ åˆ°æ‰¹é‡å¤„ç†åˆ—è¡¨
                merged_data_list.append(merged_data)
            
            # æ‰¹é‡æ’å…¥æˆ–æ›´æ–°æ•°æ®
            self._batch_upsert_financial_reports(merged_data_list)
                
        except Exception as e:
            print(f"âŒ åˆå¹¶è´¢åŠ¡æŠ¥è¡¨æ•°æ®å¤±è´¥: {e}")
            raise
    
    def _batch_upsert_financial_reports(self, data_list):
        """æ‰¹é‡æ’å…¥æˆ–æ›´æ–°è´¢åŠ¡æŠ¥è¡¨æ•°æ®ï¼Œæ”¯æŒå¤±è´¥é™çº§åˆ°é€æ¡æ’å…¥"""
        if not data_list:
            return

        start_time = time.perf_counter()
        try:
            # æ„å»ºæ‰¹é‡UPSERT SQLè¯­å¥
            columns = list(data_list[0].keys())
            placeholders = [f":{col}" for col in columns]

            # æ’é™¤ä¸»é”®å’Œupdated_atå­—æ®µï¼Œè¿™äº›å­—æ®µä¸åº”åœ¨DO UPDATE SETä¸­è¢«EXCLUDED
            update_cols = [f"{col} = EXCLUDED.{col}" for col in columns if col not in ['ts_code', 'end_date', 'report_type']]
            update_set_clause = ', '.join(update_cols)

            sql = f"""
            INSERT INTO financial_reports ({', '.join(columns)})
            VALUES ({', '.join(placeholders)})
            ON CONFLICT (ts_code, end_date, report_type)
            DO UPDATE SET
                {update_set_clause},
                updated_at = CURRENT_TIMESTAMP
            """

            with self.engine.connect() as conn:
                with conn.begin(): # å¼€å¯äº‹åŠ¡
                    conn.execute(text(sql), data_list)
            end_time = time.perf_counter()
            print(f"âœ… æ‰¹é‡æ’å…¥ {len(data_list)} æ¡è´¢åŠ¡æŠ¥è¡¨æ•°æ®æˆåŠŸï¼Œè€—æ—¶: {end_time - start_time:.4f} ç§’")

        except Exception as e:
            print(f"âŒ æ‰¹é‡æ’å…¥è´¢åŠ¡æŠ¥è¡¨æ•°æ®å¤±è´¥: {e}ï¼Œå°è¯•å›é€€åˆ°é€æ¡æ’å…¥æ¨¡å¼...")
            # é™çº§åˆ°é€æ¡æ’å…¥
            self._fallback_upsert_financial_reports(data_list)

    def _fallback_upsert_financial_reports(self, data_list):
        """æ‰¹é‡æ’å…¥å¤±è´¥æ—¶çš„é™çº§æ–¹æ¡ˆï¼šé€æ¡æ’å…¥è´¢åŠ¡æŠ¥è¡¨æ•°æ®"""
        print(f"å¼€å§‹é€æ¡æ’å…¥ {len(data_list)} æ¡è´¢åŠ¡æŠ¥è¡¨æ•°æ®...")
        start_time = time.perf_counter()
        success_count = 0
        for i, data in enumerate(data_list):
            try:
                columns = list(data.keys())
                placeholders = [f":{col}" for col in columns]
                update_cols = [f"{col} = EXCLUDED.{col}" for col in columns if col not in ['ts_code', 'end_date', 'report_type']]
                update_set_clause = ', '.join(update_cols)

                sql = f"""
                INSERT INTO financial_reports ({', '.join(columns)})
                VALUES ({', '.join(placeholders)})
                ON CONFLICT (ts_code, end_date, report_type)
                DO UPDATE SET
                    {update_set_clause},
                    updated_at = CURRENT_TIMESTAMP
                """
                with self.engine.connect() as conn:
                    with conn.begin(): # å¼€å¯äº‹åŠ¡
                        conn.execute(text(sql), data)
                success_count += 1
            except Exception as e:
                print(f"âŒ é€æ¡æ’å…¥ç¬¬ {i+1} æ¡æ•°æ®å¤±è´¥: {e}")
        end_time = time.perf_counter()
        print(f"âœ… é€æ¡æ’å…¥å®Œæˆï¼ŒæˆåŠŸ {success_count}/{len(data_list)} æ¡ï¼Œè€—æ—¶: {end_time - start_time:.4f} ç§’")
    

    
    @idempotent_retry()
    def sync_indicator_data(self, start_date=None):
        """åŒæ­¥æŒ‡æ ‡æ•°æ®ï¼ˆæ¯æ—¥åŸºæœ¬é¢æŒ‡æ ‡ï¼‰"""
        print("å¼€å§‹åŒæ­¥æŒ‡æ ‡æ•°æ®...")
        try:
            if start_date is None:
                start_date = self.config.get('data_sync_params.indicator_data.start_date', '20200101')
            
            batch_size = self.config.get('data_sync_params.indicator_data.batch_size', 500)
            sleep_interval = self.config.get('data_sync_params.indicator_data.sleep_interval', 0.2)
            
            # è·å–äº¤æ˜“æ—¥å†
            trade_dates = pd.read_sql(
                f"SELECT cal_date FROM trade_calendar WHERE cal_date >= '{start_date}' AND is_open = 1 ORDER BY cal_date",
                self.engine
            )['cal_date'].tolist()
            
            print(f"éœ€è¦åŒæ­¥ {len(trade_dates)} ä¸ªäº¤æ˜“æ—¥çš„æŒ‡æ ‡æ•°æ®")
            
            # åˆ†æ‰¹å¤„ç†äº¤æ˜“æ—¥
            for i, trade_date in enumerate(trade_dates):
                try:
                    trade_date_str = trade_date.strftime('%Y%m%d')
                    print(f"æ­£åœ¨åŒæ­¥ {trade_date_str} çš„æŒ‡æ ‡æ•°æ® ({i+1}/{len(trade_dates)})")
                    
                    # è·å–æ¯æ—¥åŸºæœ¬é¢æŒ‡æ ‡
                    daily_basic_df = self.pro.daily_basic(
                        trade_date=trade_date_str,
                        fields='ts_code,trade_date,turnover_rate,turnover_rate_f,volume_ratio,pe,pe_ttm,pb,ps,ps_ttm,dv_ratio,dv_ttm,total_share,float_share,free_share,total_mv,circ_mv'
                    )
                    
                    if not daily_basic_df.empty:
                        # å°†æ•°æ®æ’å…¥åˆ°æ•°æ®åº“
                        daily_basic_df.to_sql(
                            'daily_basic',
                            self.engine,
                            if_exists='append',
                            index=False,
                            method='multi'
                        )
                        print(f"âœ… {trade_date_str} æŒ‡æ ‡æ•°æ®åŒæ­¥å®Œæˆï¼Œå…± {len(daily_basic_df)} æ¡è®°å½•")
                    
                    time.sleep(sleep_interval)
                    
                except Exception as e:
                    print(f"âŒ åŒæ­¥ {trade_date_str} æŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")
                    continue
            
            print("âœ… æŒ‡æ ‡æ•°æ®åŒæ­¥å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æŒ‡æ ‡æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            raise
    
    @idempotent_retry()
    def sync_sw_industry(self, level='L1'):
        """
        åŒæ­¥ç”³ä¸‡è¡Œä¸šåˆ†ç±»æ•°æ®
        
        Args:
            level (str): è¡Œä¸šå±‚çº§ï¼Œå¯é€‰ 'L1', 'L2', 'L3'
        """
        logger.info(f"å¼€å§‹åŒæ­¥ç”³ä¸‡{level}è¡Œä¸šåˆ†ç±»æ•°æ®...")
        try:
            # éªŒè¯å‚æ•°
            if level not in ['L1', 'L2', 'L3']:
                raise ValueError(f"æ— æ•ˆçš„è¡Œä¸šå±‚çº§: {level}")
            
            sleep_interval = self.config.get('data_sync_params.sleep_interval', 0.3)
            if not isinstance(sleep_interval, (int, float)) or sleep_interval < 0:
                logger.warning("é…ç½®çš„sleep_intervalæ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼0.3ç§’")
                sleep_interval = 0.3

            # è·å–è¡Œä¸šåˆ—è¡¨
            sw_df = self.pro.index_classify(level=level, src='SW')
            if sw_df.empty:
                logger.warning(f"æœªè·å–åˆ°ç”³ä¸‡{level}è¡Œä¸šåˆ—è¡¨")
                return

            total_records = 0
            error_count = 0
            
            # æ‰¹é‡è·å–æ‰€æœ‰è¡Œä¸šçš„æˆåˆ†è‚¡
            index_codes = ','.join(sw_df['index_code'].tolist())
            all_members_df = self.pro.index_member(index_code=index_codes)
            
            if all_members_df.empty:
                logger.warning("æ‰¹é‡è·å–è¡Œä¸šæˆåˆ†è‚¡å¤±è´¥")
                return
            
            # æŒ‰è¡Œä¸šå¤„ç†æ•°æ®
            for _, sw_row in sw_df.iterrows():
                try:
                    index_code = sw_row['index_code']
                    industry_name = sw_row['industry_name']
                    
                    # ä»æ‰¹é‡æ•°æ®ä¸­ç­›é€‰å½“å‰è¡Œä¸š
                    members_df = all_members_df[all_members_df['index_code'] == index_code]
                    
                    if members_df.empty:
                        logger.warning(f"è¡Œä¸š {industry_name} æ— æˆåˆ†è‚¡æ•°æ®")
                        continue

                    # æ•°æ®éªŒè¯
                    if 'ts_code' not in members_df.columns or members_df['ts_code'].isnull().all():
                        logger.warning(f"è¡Œä¸š {industry_name} æ•°æ®æ— æ•ˆï¼Œç¼ºå°‘ts_codeå­—æ®µ")
                        continue
                    
                    # æ·»åŠ è¡Œä¸šå±‚çº§ä¿¡æ¯
                    if level == 'L1':
                        members_df['sw_l1'] = industry_name
                    elif level == 'L2':
                        members_df['sw_l2'] = industry_name
                    elif level == 'L3':
                        members_df['sw_l3'] = industry_name

                    # ç¡®ä¿æ‰€æœ‰å±‚çº§å­—æ®µå­˜åœ¨
                    for col in ['sw_l1', 'sw_l2', 'sw_l3']:
                        if col not in members_df.columns:
                            members_df[col] = None

                    # æ•°æ®å»é‡
                    members_df = members_df.drop_duplicates(
                        subset=['ts_code', 'trade_date', 'sw_l1', 'sw_l2', 'sw_l3']
                    )

                    # æ‰¹é‡UPSERT
                    with self.engine.connect() as conn:
                        for _, row in members_df.iterrows():
                            conn.execute(text("""
                                INSERT INTO sw_industry_history 
                                (ts_code, trade_date, sw_l1, sw_l2, sw_l3, in_date, out_date)
                                VALUES 
                                (:ts_code, :trade_date, :sw_l1, :sw_l2, :sw_l3, :in_date, :out_date)
                                ON CONFLICT (ts_code, trade_date, sw_l1, sw_l2, sw_l3)
                                DO UPDATE SET
                                    in_date = EXCLUDED.in_date,
                                    out_date = EXCLUDED.out_date
                            """), {
                                'ts_code': row['ts_code'],
                                'trade_date': row.get('trade_date', datetime.now().date()),
                                'sw_l1': row.get('sw_l1'),
                                'sw_l2': row.get('sw_l2'),
                                'sw_l3': row.get('sw_l3'),
                                'in_date': row.get('in_date'),
                                'out_date': row.get('out_date')
                            })
                        conn.commit()
                        
                        total_records += len(members_df)
                        logger.info(f"åŒæ­¥ {industry_name}: {len(members_df)} åªè‚¡ç¥¨")
                        
                except Exception as e:
                    error_count += 1
                    logger.error(f"å¤„ç†è¡Œä¸š {industry_name} æ—¶å‡ºé”™: {e}")
                    continue

                # é¢‘ç‡æ§åˆ¶
                time.sleep(sleep_interval)

            logger.info(f"ç”³ä¸‡{level}è¡Œä¸šåˆ†ç±»æ•°æ®åŒæ­¥å®Œæˆï¼Œå…±å¤„ç† {total_records} æ¡è®°å½•ï¼Œ{error_count} ä¸ªè¡Œä¸šå‡ºé”™")
            
        except Exception as e:
            logger.error(f"ç”³ä¸‡{level}è¡Œä¸šåˆ†ç±»æ•°æ®åŒæ­¥å¤±è´¥: {e}", exc_info=True)
            raise

    def sync_sw_industry_full(self):
        """
        åŒæ­¥å®Œæ•´çš„ç”³ä¸‡è¡Œä¸šåˆ†ç±»æ•°æ®ï¼ˆL1, L2, L3ï¼‰
        """
        logger.info("å¼€å§‹åŒæ­¥å®Œæ•´çš„ç”³ä¸‡è¡Œä¸šåˆ†ç±»æ•°æ®...")
        try:
            # æŒ‰å±‚çº§åŒæ­¥
            for level in ['L1', 'L2', 'L3']:
                try:
                    self.sync_sw_industry(level=level)
                except Exception as e:
                    logger.error(f"åŒæ­¥ç”³ä¸‡{level}è¡Œä¸šæ•°æ®å¤±è´¥: {e}")
                    continue
                    
            logger.info("å®Œæ•´çš„ç”³ä¸‡è¡Œä¸šåˆ†ç±»æ•°æ®åŒæ­¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å®Œæ•´çš„ç”³ä¸‡è¡Œä¸šåˆ†ç±»æ•°æ®åŒæ­¥å¤±è´¥: {e}", exc_info=True)
            raise

    def update_sw_industry_for_stocks(self, stock_list=None):
        """
        æ›´æ–°æŒ‡å®šè‚¡ç¥¨åˆ—è¡¨çš„ç”³ä¸‡è¡Œä¸šåˆ†ç±»å†å²æ•°æ®
        
        Args:
            stock_list (list): è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™æ›´æ–°æ‰€æœ‰è‚¡ç¥¨
        """
        logger.info("å¼€å§‹æ›´æ–°è‚¡ç¥¨ç”³ä¸‡è¡Œä¸šåˆ†ç±»å†å²æ•°æ®...")
        try:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè‚¡ç¥¨åˆ—è¡¨ï¼Œåˆ™è·å–æ‰€æœ‰è‚¡ç¥¨
            if stock_list is None:
                stocks_df = pd.read_sql("SELECT ts_code FROM stock_basic", self.engine)
                stock_list = stocks_df['ts_code'].tolist()
            
            if not stock_list:
                logger.warning("è‚¡ç¥¨åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•æ›´æ–°è¡Œä¸šåˆ†ç±»")
                return
            
            total_stocks = len(stock_list)
            processed_count = 0
            error_count = 0
            
            # åˆ†æ‰¹å¤„ç†
            batch_size = self.config.get('data_sync_params.batch_size', 1000)
            
            for i in range(0, total_stocks, batch_size):
                batch_stocks = stock_list[i:i+batch_size]
                logger.info(f"å¤„ç†è‚¡ç¥¨æ‰¹æ¬¡ {i//batch_size + 1}/{(total_stocks-1)//batch_size + 1}")
                
                try:
                    # æ‰¹é‡è·å–è¡Œä¸šæ•°æ®
                    batch_str = ','.join(batch_stocks)
                    industry_df = self.pro.index_member(ts_code=batch_str, src='SW')
                    
                    if not industry_df.empty:
                        # æ‰¹é‡æ’å…¥/æ›´æ–°
                        with self.engine.connect() as conn:
                            for _, row in industry_df.iterrows():
                                conn.execute(text("""
                                    INSERT INTO sw_industry_history 
                                    (ts_code, trade_date, sw_l1, sw_l2, sw_l3, in_date, out_date)
                                    VALUES 
                                    (:ts_code, :trade_date, :sw_l1, :sw_l2, :sw_l3, :in_date, :out_date)
                                    ON CONFLICT (ts_code, trade_date, sw_l1, sw_l2, sw_l3)
                                    DO UPDATE SET
                                        in_date = EXCLUDED.in_date,
                                        out_date = EXCLUDED.out_date
                                """), {
                                    'ts_code': row['ts_code'],
                                    'trade_date': row.get('trade_date', datetime.now().date()),
                                    'sw_l1': row.get('sw_l1'),
                                    'sw_l2': row.get('sw_l2'),
                                    'sw_l3': row.get('sw_l3'),
                                    'in_date': row.get('in_date'),
                                    'out_date': row.get('out_date')
                                })
                            conn.commit()
                        
                            processed_count += len(industry_df)
                    
                except Exception as e:
                    error_count += 1
                    logger.error(f"å¤„ç†è‚¡ç¥¨æ‰¹æ¬¡ {i//batch_size + 1} æ—¶å‡ºé”™: {e}")
                    continue
                
                # æ§åˆ¶APIè°ƒç”¨é¢‘ç‡
                time.sleep(self.config.get('data_sync_params.sleep_interval', 0.3))
            
            logger.info(f"è‚¡ç¥¨ç”³ä¸‡è¡Œä¸šåˆ†ç±»å†å²æ•°æ®æ›´æ–°å®Œæˆï¼Œå…±å¤„ç† {processed_count} æ¡è®°å½•ï¼Œ{error_count} ä¸ªæ‰¹æ¬¡å‡ºé”™")
            
        except Exception as e:
            logger.error(f"è‚¡ç¥¨ç”³ä¸‡è¡Œä¸šåˆ†ç±»å†å²æ•°æ®æ›´æ–°å¤±è´¥: {e}", exc_info=True)
            raise
    
    def full_sync(self):
        """å®Œæ•´åŒæ­¥ï¼šåŸºæœ¬ä¿¡æ¯ + äº¤æ˜“æ—¥å† + æ—¥çº¿æ•°æ®"""
        print("ğŸš€ å¼€å§‹å®Œæ•´æ•°æ®åŒæ­¥...")
        try:
            # 1. åŒæ­¥è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            self.sync_stock_basic()
            
            # 2. åŒæ­¥äº¤æ˜“æ—¥å†
            self.sync_trade_calendar()
            
            # 3. æ›´æ–°æ—¥çº¿æ•°æ®
            self.update_daily_data()
            
            # 4. åŒæ­¥è´¢åŠ¡æ•°æ®
            self.sync_financial_data()
            
            # 5. åŒæ­¥æŒ‡æ ‡æ•°æ®
            self.sync_indicator_data()
            
            # 6. åŒæ­¥ç”³ä¸‡è¡Œä¸šåˆ†ç±»æ•°æ®
            self.sync_sw_industry_full()
            
            print("ğŸ‰ å®Œæ•´æ•°æ®åŒæ­¥å®Œæˆï¼")
            
        except Exception as e:
            print(f"ğŸ’¥ å®Œæ•´æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            raise

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Tushareæ•°æ®åŒæ­¥å·¥å…·')
    parser.add_argument('--mode', choices=['basic', 'calendar', 'daily', 'financial', 'indicator', 'industry', 'industry_full', 'industry_update', 'full'], 
                       default='daily', help='åŒæ­¥æ¨¡å¼')
    parser.add_argument('--days', type=int, 
                       help='æ—¥çº¿æ•°æ®æ›´æ–°å¤©æ•°ï¼ˆä»…åœ¨dailyæ¨¡å¼ä¸‹æœ‰æ•ˆï¼‰')
    parser.add_argument('--start-date', type=str,
                       help='å¼€å§‹æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYYMMDDï¼Œé€‚ç”¨äºfinancialå’Œindicatoræ¨¡å¼ï¼‰')
    parser.add_argument('--level', choices=['L1', 'L2', 'L3'], default='L1',
                       help='è¡Œä¸šå±‚çº§ï¼ˆä»…åœ¨industryæ¨¡å¼ä¸‹æœ‰æ•ˆï¼‰')
    parser.add_argument('--stock-file', type=str,
                       help='è‚¡ç¥¨ä»£ç æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºindustry_updateæ¨¡å¼ï¼‰')
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºåŒæ­¥å™¨å®ä¾‹
        synchronizer = TushareSynchronizer()
        
        # æ ¹æ®æ¨¡å¼æ‰§è¡Œä¸åŒçš„åŒæ­¥ä»»åŠ¡
        if args.mode == 'basic':
            synchronizer.sync_stock_basic()
        elif args.mode == 'calendar':
            synchronizer.sync_trade_calendar()
        elif args.mode == 'daily':
            synchronizer.update_daily_data(max_days=args.days)
        elif args.mode == 'financial':
            synchronizer.sync_financial_data(start_date=args.start_date)
        elif args.mode == 'indicator':
            synchronizer.sync_indicator_data(start_date=args.start_date)
        elif args.mode == 'industry':
            synchronizer.sync_sw_industry(level=args.level)
        elif args.mode == 'industry_full':
            synchronizer.sync_sw_industry_full()
        elif args.mode == 'industry_update':
            stock_list = None
            if args.stock_file:
                try:
                    with open(args.stock_file, 'r') as f:
                        stock_list = [line.strip() for line in f if line.strip()]
                    logger.info(f"ä»æ–‡ä»¶åŠ è½½äº† {len(stock_list)} ä¸ªè‚¡ç¥¨ä»£ç ")
                except Exception as e:
                    logger.error(f"è¯»å–è‚¡ç¥¨æ–‡ä»¶å¤±è´¥: {e}")
            
            synchronizer.update_sw_industry_for_stocks(stock_list=stock_list)
        elif args.mode == 'full':
            synchronizer.full_sync()
            
    except Exception as e:
        print(f"âŒ æ•°æ®åŒæ­¥å¤±è´¥: {e}")
        raise
