import asyncio
import json
import logging
import os
import tempfile
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List

import pytest

#!/usr/bin/env python3
"""
ç›‘æ§æ•°æ®å¯¼å‡ºå’ŒæŠ¥å‘ŠåŠŸèƒ½æµ‹è¯•

æµ‹è¯•å¯¼å‡ºæœåŠ¡çš„å„é¡¹åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ•°æ®å¯¼å‡ºã€æŠ¥å‘Šç”Ÿæˆã€é‚®ä»¶å‘é€ç­‰

ä½œè€…: StockSchool Team
åˆ›å»ºæ—¶é—´: 2025-01-02
"""


# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# å¯¼å…¥æµ‹è¯•æ¨¡å—
try:
    from src.services.export_service import (
        DataExporter,
        EmailService,
        ExportConfig,
        ExportService,
        PDFReportGenerator,
        ReportGenerator,
        ScheduledReportService,
        create_export_service,
    )
    from src.services.monitoring_service import MonitoringService
except ImportError as e:
    logger.error(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    pytest.skip(f"è·³è¿‡æµ‹è¯•ï¼Œå¯¼å…¥æ¨¡å—å¤±è´¥: {e}")


class MockMonitoringService:
    """æ¨¡æ‹Ÿç›‘æ§æœåŠ¡"""

    async def get_system_health(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿç³»ç»Ÿå¥åº·æ•°æ®"""
        return {
            "cpu_usage": 75.5,
            "memory_usage": 68.2,
            "disk_usage": 45.8,
            "database_status": "connected",
            "redis_status": "connected",
            "celery_status": "running",
            "api_status": "healthy",
        }

    async def query_metrics_with_cache(
        self, metric_names: List[str], start_time: datetime, end_time: datetime, **kwargs
    ) -> List[Dict[str, Any]]:
        """æ¨¡æ‹ŸæŒ‡æ ‡æ•°æ®"""
        metrics_data = []

        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        current_time = start_time
        while current_time <= end_time:
            for metric_name in metric_names:
                if metric_name == "cpu_usage":
                    value = 70 + (hash(str(current_time)) % 20)
                elif metric_name == "memory_usage":
                    value = 60 + (hash(str(current_time)) % 25)
                elif metric_name == "disk_usage":
                    value = 40 + (hash(str(current_time)) % 15)
                else:
                    value = 50 + (hash(str(current_time)) % 30)

                metrics_data.append(
                    {
                        "timestamp": current_time,
                        "metric_name": metric_name,
                        "metric_value": value,
                        "metric_type": "gauge",
                        "metric_unit": "%",
                        "source_component": "system",
                        "labels": {"host": "localhost"},
                    }
                )

            current_time += timedelta(minutes=5)

        return metrics_data

    async def get_active_alerts(self, limit: int = 100) -> List[Dict[str, Any]]:
        """æ¨¡æ‹Ÿå‘Šè­¦æ•°æ®"""
        return [
            {
                "alert_id": "alert_001",
                "severity": "warning",
                "title": "CPUä½¿ç”¨ç‡è¿‡é«˜",
                "description": "CPUä½¿ç”¨ç‡è¶…è¿‡80%",
                "created_at": datetime.now() - timedelta(hours=2),
                "status": "active",
            },
            {
                "alert_id": "alert_002",
                "severity": "critical",
                "title": "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜",
                "description": "å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡90%",
                "created_at": datetime.now() - timedelta(hours=1),
                "status": "active",
            },
        ]


class ExportFunctionalityTest:
    """å¯¼å‡ºåŠŸèƒ½æµ‹è¯•ç±»"""

    def __init__(self):
        """æ–¹æ³•æè¿°"""

        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.temp_dir = tempfile.mkdtemp(prefix="export_test_")
        self.logger.info(f"æµ‹è¯•ä¸´æ—¶ç›®å½•: {self.temp_dir}")

        # åˆ›å»ºæµ‹è¯•é…ç½®
        self.config = ExportConfig(
            export_dir=os.path.join(self.temp_dir, "exports"),
            temp_dir=os.path.join(self.temp_dir, "temp"),
            max_file_size_mb=10,
            max_records_per_export=1000,
            # é‚®ä»¶é…ç½®ï¼ˆæµ‹è¯•æ—¶ä¸å‘é€çœŸå®é‚®ä»¶ï¼‰
            smtp_host="localhost",
            smtp_port=587,
            smtp_username="test@example.com",
            smtp_password="test_password",
            smtp_use_tls=False,
        )

        # åˆ›å»ºæ¨¡æ‹Ÿç›‘æ§æœåŠ¡
        self.mock_monitoring_service = MockMonitoringService()

        # æµ‹è¯•ç»“æœ
        self.test_results = {
            "csv_export": False,
            "excel_export": False,
            "json_export": False,
            "pdf_report": False,
            "email_service": False,
            "scheduled_report": False,
            "data_integrity": False,
            "format_validation": False,
        }

    async def run_all_tests(self) -> Dict[str, bool]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        self.logger.info("ğŸš€ å¼€å§‹å¯¼å‡ºåŠŸèƒ½æµ‹è¯•...")

        try:
            # æµ‹è¯•æ•°æ®å¯¼å‡º
            await self.test_csv_export()
            await self.test_excel_export()
            await self.test_json_export()

            # æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
            await self.test_pdf_report_generation()

            # æµ‹è¯•é‚®ä»¶æœåŠ¡
            await self.test_email_service()

            # æµ‹è¯•å®šæ—¶æŠ¥å‘Š
            await self.test_scheduled_report()

            # æµ‹è¯•æ•°æ®å®Œæ•´æ€§
            await self.test_data_integrity()

            # æµ‹è¯•æ ¼å¼éªŒè¯
            await self.test_format_validation()

        except Exception as e:
            self.logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

        # è¾“å‡ºæµ‹è¯•ç»“æœ
        self.print_test_results()

        return self.test_results

    async def test_csv_export(self):
        """æµ‹è¯•CSVå¯¼å‡ºåŠŸèƒ½"""
        self.logger.info("ğŸ“Š æµ‹è¯•CSVå¯¼å‡ºåŠŸèƒ½...")

        try:
            # åˆ›å»ºå¯¼å‡ºæœåŠ¡
            export_service = await create_export_service(
                config=self.config, monitoring_service=self.mock_monitoring_service
            )

            # å‡†å¤‡æµ‹è¯•æ•°æ®
            start_time = datetime.now() - timedelta(hours=1)
            end_time = datetime.now()

            # å¯¼å‡ºCSVæ•°æ®
            file_path = await export_service.export_monitoring_data(
                format_type="csv",
                start_time=start_time,
                end_time=end_time,
                metric_names=["cpu_usage", "memory_usage"],
                filename="test_csv_export",
            )

            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if Path(file_path).exists():
                # éªŒè¯æ–‡ä»¶å†…å®¹
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    if "cpu_usage" in content and "memory_usage" in content:
                        self.test_results["csv_export"] = True
                        self.logger.info("âœ… CSVå¯¼å‡ºæµ‹è¯•é€šè¿‡")
                    else:
                        self.logger.error("âŒ CSVæ–‡ä»¶å†…å®¹éªŒè¯å¤±è´¥")
            else:
                self.logger.error("âŒ CSVæ–‡ä»¶æœªç”Ÿæˆ")

        except Exception as e:
            self.logger.error(f"âŒ CSVå¯¼å‡ºæµ‹è¯•å¤±è´¥: {e}")

    async def test_excel_export(self):
        """æµ‹è¯•Excelå¯¼å‡ºåŠŸèƒ½"""
        self.logger.info("ğŸ“ˆ æµ‹è¯•Excelå¯¼å‡ºåŠŸèƒ½...")

        try:
            # æ£€æŸ¥Excelæ”¯æŒ
            try:
                import openpyxl
                import pandas as pd

                excel_available = True
            except ImportError:
                excel_available = False
                self.logger.warning("âš ï¸ Excelä¾èµ–ä¸å¯ç”¨ï¼Œè·³è¿‡Excelå¯¼å‡ºæµ‹è¯•")
                return

            if excel_available:
                # åˆ›å»ºå¯¼å‡ºæœåŠ¡
                export_service = await create_export_service(
                    config=self.config, monitoring_service=self.mock_monitoring_service
                )

                # å‡†å¤‡æµ‹è¯•æ•°æ®
                start_time = datetime.now() - timedelta(hours=1)
                end_time = datetime.now()

                # å¯¼å‡ºExcelæ•°æ®
                file_path = await export_service.export_monitoring_data(
                    format_type="excel",
                    start_time=start_time,
                    end_time=end_time,
                    metric_names=["cpu_usage", "memory_usage"],
                    filename="test_excel_export",
                )

                # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if Path(file_path).exists():
                    self.test_results["excel_export"] = True
                    self.logger.info("âœ… Excelå¯¼å‡ºæµ‹è¯•é€šè¿‡")
                else:
                    self.logger.error("âŒ Excelæ–‡ä»¶æœªç”Ÿæˆ")

        except Exception as e:
            self.logger.error(f"âŒ Excelå¯¼å‡ºæµ‹è¯•å¤±è´¥: {e}")

    async def test_json_export(self):
        """æµ‹è¯•JSONå¯¼å‡ºåŠŸèƒ½"""
        self.logger.info("ğŸ“„ æµ‹è¯•JSONå¯¼å‡ºåŠŸèƒ½...")

        try:
            # åˆ›å»ºå¯¼å‡ºæœåŠ¡
            export_service = await create_export_service(
                config=self.config, monitoring_service=self.mock_monitoring_service
            )

            # å‡†å¤‡æµ‹è¯•æ•°æ®
            start_time = datetime.now() - timedelta(hours=1)
            end_time = datetime.now()

            # å¯¼å‡ºJSONæ•°æ®
            file_path = await export_service.export_monitoring_data(
                format_type="json",
                start_time=start_time,
                end_time=end_time,
                metric_names=["cpu_usage", "memory_usage"],
                filename="test_json_export",
            )

            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if Path(file_path).exists():
                # éªŒè¯JSONæ ¼å¼
                with open(file_path, "r", encoding="utf-8") as f:
                    try:
                        data = json.load(f)
                        if isinstance(data, list) and len(data) > 0:
                            self.test_results["json_export"] = True
                            self.logger.info("âœ… JSONå¯¼å‡ºæµ‹è¯•é€šè¿‡")
                        else:
                            self.logger.error("âŒ JSONæ•°æ®æ ¼å¼éªŒè¯å¤±è´¥")
                    except json.JSONDecodeError:
                        self.logger.error("âŒ JSONæ–‡ä»¶æ ¼å¼æ— æ•ˆ")
            else:
                self.logger.error("âŒ JSONæ–‡ä»¶æœªç”Ÿæˆ")

        except Exception as e:
            self.logger.error(f"âŒ JSONå¯¼å‡ºæµ‹è¯•å¤±è´¥: {e}")

    async def test_pdf_report_generation(self):
        """æµ‹è¯•PDFæŠ¥å‘Šç”ŸæˆåŠŸèƒ½"""
        self.logger.info("ğŸ“‹ æµ‹è¯•PDFæŠ¥å‘Šç”ŸæˆåŠŸèƒ½...")

        try:
            # æ£€æŸ¥PDFæ”¯æŒ
            try:
                from reportlab.lib import colors

                pdf_available = True
            except ImportError:
                pdf_available = False
                self.logger.warning("âš ï¸ PDFä¾èµ–ä¸å¯ç”¨ï¼Œè·³è¿‡PDFæŠ¥å‘Šæµ‹è¯•")
                return

            if pdf_available:
                # åˆ›å»ºå¯¼å‡ºæœåŠ¡
                export_service = await create_export_service(
                    config=self.config, monitoring_service=self.mock_monitoring_service
                )

                # å‡†å¤‡æµ‹è¯•æ•°æ®
                start_time = datetime.now() - timedelta(hours=1)
                end_time = datetime.now()

                # ç”ŸæˆPDFæŠ¥å‘Š
                file_path = await export_service.generate_report(
                    report_type="system_health",
                    start_time=start_time,
                    end_time=end_time,
                    format_type="pdf",
                    filename="test_pdf_report",
                )

                # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if Path(file_path).exists():
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆPDFæ–‡ä»¶åº”è¯¥æœ‰ä¸€å®šå¤§å°ï¼‰
                    file_size = Path(file_path).stat().st_size
                    if file_size > 1000:  # è‡³å°‘1KB
                        self.test_results["pdf_report"] = True
                        self.logger.info("âœ… PDFæŠ¥å‘Šç”Ÿæˆæµ‹è¯•é€šè¿‡")
                    else:
                        self.logger.error("âŒ PDFæ–‡ä»¶å¤§å°å¼‚å¸¸")
                else:
                    self.logger.error("âŒ PDFæ–‡ä»¶æœªç”Ÿæˆ")

        except Exception as e:
            self.logger.error(f"âŒ PDFæŠ¥å‘Šç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")

    async def test_email_service(self):
        """æµ‹è¯•é‚®ä»¶æœåŠ¡åŠŸèƒ½"""
        self.logger.info("ğŸ“§ æµ‹è¯•é‚®ä»¶æœåŠ¡åŠŸèƒ½...")

        try:
            # åˆ›å»ºé‚®ä»¶æœåŠ¡ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿé…ç½®ï¼‰
            email_service = EmailService(self.config)

            # å‡†å¤‡æµ‹è¯•æŠ¥å‘Šæ•°æ®
            report_data = {
                "report_info": {
                    "title": "æµ‹è¯•æŠ¥å‘Š",
                    "generated_at": datetime.now(),
                    "period": {"start_time": datetime.now() - timedelta(hours=1), "end_time": datetime.now()},
                },
                "summary": {
                    "overall_status": "healthy",
                    "total_alerts": 2,
                    "critical_alerts": 1,
                    "avg_cpu_usage": 75.5,
                    "avg_memory_usage": 68.2,
                    "avg_disk_usage": 45.8,
                },
                "recommendations": ["å»ºè®®ä¼˜åŒ–CPUä½¿ç”¨ç‡", "å»ºè®®æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ"],
            }

            # æµ‹è¯•é‚®ä»¶æ­£æ–‡ç”Ÿæˆ
            email_body = email_service._generate_email_body(report_data)

            if "æµ‹è¯•æŠ¥å‘Š" in email_body and "healthy" in email_body:
                self.test_results["email_service"] = True
                self.logger.info("âœ… é‚®ä»¶æœåŠ¡æµ‹è¯•é€šè¿‡ï¼ˆé‚®ä»¶æ­£æ–‡ç”Ÿæˆï¼‰")
            else:
                self.logger.error("âŒ é‚®ä»¶æ­£æ–‡ç”Ÿæˆå¤±è´¥")

            # æ³¨æ„ï¼šè¿™é‡Œä¸æµ‹è¯•å®é™…çš„é‚®ä»¶å‘é€ï¼Œå› ä¸ºéœ€è¦çœŸå®çš„SMTPé…ç½®

        except Exception as e:
            self.logger.error(f"âŒ é‚®ä»¶æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")

    async def test_scheduled_report(self):
        """æµ‹è¯•å®šæ—¶æŠ¥å‘ŠåŠŸèƒ½"""
        self.logger.info("â° æµ‹è¯•å®šæ—¶æŠ¥å‘ŠåŠŸèƒ½...")

        try:
            # åˆ›å»ºå®šæ—¶æŠ¥å‘ŠæœåŠ¡
            scheduled_service = ScheduledReportService(self.config, self.mock_monitoring_service)

            # æµ‹è¯•æŠ¥å‘Šæ•°æ®ç”Ÿæˆï¼ˆä¸å®é™…å‘é€é‚®ä»¶ï¼‰
            start_time = datetime.now() - timedelta(days=1)
            end_time = datetime.now()

            # ç”ŸæˆæŠ¥å‘Šæ•°æ®
            report_data = await scheduled_service.report_generator.generate_system_health_report(
                start_time, end_time, self.mock_monitoring_service
            )

            # éªŒè¯æŠ¥å‘Šæ•°æ®ç»“æ„
            required_keys = ["report_info", "summary", "health_data", "metrics_data", "alerts_data"]
            if all(key in report_data for key in required_keys):
                self.test_results["scheduled_report"] = True
                self.logger.info("âœ… å®šæ—¶æŠ¥å‘Šæµ‹è¯•é€šè¿‡ï¼ˆæŠ¥å‘Šæ•°æ®ç”Ÿæˆï¼‰")
            else:
                self.logger.error("âŒ æŠ¥å‘Šæ•°æ®ç»“æ„éªŒè¯å¤±è´¥")

        except Exception as e:
            self.logger.error(f"âŒ å®šæ—¶æŠ¥å‘Šæµ‹è¯•å¤±è´¥: {e}")

    async def test_data_integrity(self):
        """æµ‹è¯•æ•°æ®å®Œæ•´æ€§"""
        self.logger.info("ğŸ” æµ‹è¯•æ•°æ®å®Œæ•´æ€§...")

        try:
            # åˆ›å»ºå¯¼å‡ºæœåŠ¡
            export_service = await create_export_service(
                config=self.config, monitoring_service=self.mock_monitoring_service
            )

            # å‡†å¤‡æµ‹è¯•æ•°æ®
            start_time = datetime.now() - timedelta(hours=1)
            end_time = datetime.now()
            metric_names = ["cpu_usage", "memory_usage"]

            # è·å–åŸå§‹æ•°æ®
            original_data = await self.mock_monitoring_service.query_metrics_with_cache(
                metric_names=metric_names, start_time=start_time, end_time=end_time
            )

            # å¯¼å‡ºJSONæ•°æ®
            json_file_path = await export_service.export_monitoring_data(
                format_type="json",
                start_time=start_time,
                end_time=end_time,
                metric_names=metric_names,
                filename="integrity_test",
            )

            # è¯»å–å¯¼å‡ºçš„æ•°æ®
            with open(json_file_path, "r", encoding="utf-8") as f:
                exported_data = json.load(f)

            # æ¯”è¾ƒæ•°æ®å®Œæ•´æ€§
            if len(original_data) == len(exported_data):
                # æ£€æŸ¥å…³é”®å­—æ®µ
                integrity_check = True
                for i, (orig, exp) in enumerate(zip(original_data, exported_data)):
                    if orig["metric_name"] != exp["metric_name"] or orig["metric_value"] != exp["metric_value"]:
                        integrity_check = False
                        break

                if integrity_check:
                    self.test_results["data_integrity"] = True
                    self.logger.info("âœ… æ•°æ®å®Œæ•´æ€§æµ‹è¯•é€šè¿‡")
                else:
                    self.logger.error("âŒ æ•°æ®å†…å®¹ä¸åŒ¹é…")
            else:
                self.logger.error(f"âŒ æ•°æ®æ•°é‡ä¸åŒ¹é…: åŸå§‹{len(original_data)}, å¯¼å‡º{len(exported_data)}")

        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®å®Œæ•´æ€§æµ‹è¯•å¤±è´¥: {e}")

    async def test_format_validation(self):
        """æµ‹è¯•æ ¼å¼éªŒè¯"""
        self.logger.info("âœ… æµ‹è¯•æ ¼å¼éªŒè¯...")

        try:
            # åˆ›å»ºå¯¼å‡ºæœåŠ¡
            export_service = await create_export_service(
                config=self.config, monitoring_service=self.mock_monitoring_service
            )

            # æµ‹è¯•æ— æ•ˆæ ¼å¼
            try:
                await export_service.export_monitoring_data(
                    format_type="invalid_format",
                    start_time=datetime.now() - timedelta(hours=1),
                    end_time=datetime.now(),
                    metric_names=["cpu_usage"],
                )
                self.logger.error("âŒ æ ¼å¼éªŒè¯å¤±è´¥ï¼šåº”è¯¥æ‹’ç»æ— æ•ˆæ ¼å¼")
            except ValueError as e:
                if "ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼" in str(e):
                    self.test_results["format_validation"] = True
                    self.logger.info("âœ… æ ¼å¼éªŒè¯æµ‹è¯•é€šè¿‡")
                else:
                    self.logger.error(f"âŒ æ ¼å¼éªŒè¯é”™è¯¯ä¿¡æ¯ä¸æ­£ç¡®: {e}")

        except Exception as e:
            self.logger.error(f"âŒ æ ¼å¼éªŒè¯æµ‹è¯•å¤±è´¥: {e}")

    def print_test_results(self):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        self.logger.info("\n" + "=" * 50)
        self.logger.info("ğŸ“Š å¯¼å‡ºåŠŸèƒ½æµ‹è¯•ç»“æœæ±‡æ€»")
        self.logger.info("=" * 50)

        total_tests = len(self.test_results)
        passed_tests = sum(self.test_results.values())

        for test_name, result in self.test_results.items():
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            self.logger.info(f"{test_name.ljust(20)}: {status}")

        self.logger.info("-" * 50)
        self.logger.info(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        self.logger.info(f"é€šè¿‡æ•°é‡: {passed_tests}")
        self.logger.info(f"å¤±è´¥æ•°é‡: {total_tests - passed_tests}")
        self.logger.info(f"é€šè¿‡ç‡: {(passed_tests/total_tests)*100:.1f}%")

        if passed_tests == total_tests:
            self.logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        else:
            self.logger.warning("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")

    def cleanup(self):
        """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
        try:
            import shutil

            shutil.rmtree(self.temp_dir)
            self.logger.info(f"æ¸…ç†æµ‹è¯•ç›®å½•: {self.temp_dir}")
        except Exception as e:
            self.logger.warning(f"æ¸…ç†æµ‹è¯•ç›®å½•å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç›‘æ§æ•°æ®å¯¼å‡ºå’ŒæŠ¥å‘ŠåŠŸèƒ½æµ‹è¯•...")

    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    test_runner = ExportFunctionalityTest()

    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        results = await test_runner.run_all_tests()

        # æ£€æŸ¥æµ‹è¯•ç»“æœ
        total_tests = len(results)
        passed_tests = sum(results.values())

        print(f"\nğŸ“Š æµ‹è¯•å®Œæˆï¼é€šè¿‡ç‡: {(passed_tests/total_tests)*100:.1f}%")

        if passed_tests == total_tests:
            print("ğŸ‰ ä»»åŠ¡20ï¼šç›‘æ§æ•°æ®å¯¼å‡ºå’ŒæŠ¥å‘ŠåŠŸèƒ½ - å®ç°å®Œæˆï¼")
            return True
        else:
            print("âš ï¸ éƒ¨åˆ†åŠŸèƒ½éœ€è¦è¿›ä¸€æ­¥å®Œå–„")
            return False

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        test_runner.cleanup()


if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)
