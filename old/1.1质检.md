### **《v1.1版 质检清单 (QC Checklist)》**



**质检指令**:

> AI，在你完成每个阶段的构建任务后，请运行以下对应的质检脚本或回答我的问题，以验证交付质量。

------



#### **第一站：数据补全与入库 (质检)**



| **质检环节 (Checkpoint)** | **检验方法 (Verification Method)**                           | **验收标准 (Acceptance Criteria)**                           |
| ------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **1. 财务数据完整性**     | **SQL查询**: `SELECT COUNT(*), COUNT(DISTINCT ts_code) FROM financial_reports WHERE end_date = '最新财报季日期';` | - 查询返回的记录数应与A股上市公司数量级大致相符。 - 关键财务字段（如`revenue`, `net_profit`）的非空比例应 > 95%。 |
| **2. 指标数据时效性**     | **SQL查询**: `SELECT MAX(trade_date) FROM daily_basic;`      | - 返回的日期应为最近的一个交易日。                           |
| **3. 情绪数据覆盖率**     | **人工检查**: 随机抽取几只股票，检查`market_sentiment`表中是否有其对应的情绪数据。 | - 大部分活跃股票都应能找到对应的情绪数据记录。               |

------



#### **第二站：核心因子计算 (质检)**



| **质检环节 (Checkpoint)** | **检验方法 (Verification Method)**                           | **验收标准 (Acceptance Criteria)**                           |
| ------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **4. 基本面因子正确性**   | **Spot Check (抽样检查)**:  1. 编写一个独立的短脚本，只针对一只股票（如贵州茅台）的一个财报季，手动计算其ROE。 2. 从`factor_library`表中查询出系统计算的同一期ROE值。 | - 手动计算结果与系统计算结果的误差应在合理范围内（< 0.1%）。 |
| **5. 因子分布合理性**     | **数据可视化**:  1. 编写一个脚本，从`factor_library`中随机抽取5个因子。<br>2. 为每个因子绘制其在全市场的**直方图(Histogram)**。 | - 因子分布不应有极端偏态（如所有值都挤在一个极小的区间内）。 - 经过标准化处理后，其均值应接近0，标准差应接近1。 |
| **6. 因子相关性**         | **数据分析**:  1. 编写一个脚本，计算所有因子之间的**相关系数矩阵**。 2. 使用热力图(Heatmap)进行可视化。 | - 不应存在大量相关性过高（如 `                               |

------



#### **第三站：AI模型训练与预测 (质检)**



| **质检环节 (Checkpoint)** | **检验方法 (Verification Method)**                           | **验收标准 (Acceptance Criteria)**                           |
| ------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **7. 训练流水线可复现性** | **重复运行**:  连续两次使用**完全相同**的时间段和参数运行`training_pipeline.py`。 | - 两次运行产出的模型评估报告（如AUC、夏普比率）应完全一致，证明训练过程没有随机性泄露。 |
| **8. 特征重要性一致性**   | **结果分析**:  查看`training_pipeline.py`产出的模型特征重要性列表。 | - 特征重要性排名靠前的应是那些在金融逻辑上被普遍认为有效的因子（如估值、成长性、动量等），这为模型提供了初步的可解释性。 |
| **9. 预测结果覆盖与范围** | **SQL查询**:  1. `SELECT COUNT(*) FROM prediction_results WHERE trade_date = '最新交易日';`<br>2. `SELECT MIN(score), MAX(score), AVG(score) FROM prediction_results WHERE trade_date = '最新交易日';` | - 预测结果应覆盖所有目标股票池内的股票。 - 预测分数应分布在一个合理的、非极端或非NaN的范围内。 |
| **10. 端到端流程完整性**  | **全流程运行**:  按顺序手动触发所有Celery任务：数据同步 -> 因子计算 -> 每日预测。 | - 整个流程能顺利跑通，不出现中断性错误。 - 最终的`prediction_results`表成功生成了当天的最新数据。 |